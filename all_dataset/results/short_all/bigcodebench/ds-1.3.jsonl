{"task_id": "BigCodeBench/13", "solution": "import subprocess\nimport ftplib\nimport os\n\ndef task_func(ftp_server='ftp.dlptest.com', ftp_user='dlpuser', ftp_password='rNrKYTX9g7z3RgJRmxWuGHbeu', ftp_dir='/ftp/test'):\n    \"\"\"\n    \n    \"\"\"\n    # \u521b\u5efaFTP\u5ba2\u6237\u7aef\n    ftp = ftplib.FTP(ftp_server)\n    ftp.login(user=ftp_user, passwd=ftp_password)\n\n    # \u5207\u6362\u5230\u6307\u5b9a\u76ee\u5f55\n    ftp.cwd(ftp_dir)\n\n    # \u5217\u51fa\u76ee\u5f55\u4e2d\u7684\u6240\u6709\u6587\u4ef6\n    file_list = ftp.nlst()\n\n    # \u904d\u5386\u6587\u4ef6\u5217\u8868\n    for file_name in file_list:\n        # \u4e0b\u8f7d\u6587\u4ef6\n        with open(file_name, 'wb') as file:\n            ftp.retrbinary('RETR ' + file_name, file.write)\n\n    # \u9000\u51faFTP\u670d\u52a1\u5668\n    ftp.quit()\n\n    # \u6253\u5370\u4e0b\u8f7d\u5b8c\u6210\u7684\u6587\u4ef6\n    print('\u4e0b\u8f7d\u5b8c\u6210\u3002')\n\n"}
{"task_id": "BigCodeBench/15", "solution": "import subprocess\nimport csv\nimport os\n\ndef task_func(commands_file_path, output_dir_path):\n    \"\"\"\n    \n    \"\"\"\n    with open(commands_file_path, 'r') as f:\n        commands = f.read().splitlines()\n\n    for command in commands:\n        process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n        stdout, stderr = process.communicate()\n\n        output_file_path = os.path.join(output_dir_path, f\"{command}.out\")\n        with open(output_file_path, 'wb') as f:\n            f.write(stdout)\n\n        error_file_path = os.path.join(output_dir_path, f\"{command}.err\")\n        with open(error_file_path, 'wb') as f:\n            f.write(stderr)\n"}
{"task_id": "BigCodeBench/17", "solution": "import subprocess\nimport psutil\nimport time\n\ndef task_func(process_name: str) -> str:\n    \"\"\"\n    \n    \"\"\"\n    # \u83b7\u53d6\u6240\u6709\u8fdb\u7a0b\n    p = psutil.process_iter(['pid', 'name'])\n    for proc in p:\n        if proc.info['name'] == process_name:\n            return proc.info['pid']\n    return None\n"}
{"task_id": "BigCodeBench/19", "solution": "import os\nimport glob\nimport zipfile\n\ndef task_func(directory):\n    \"\"\"\n    \n    \"\"\"\n    # \u83b7\u53d6\u76ee\u5f55\u4e2d\u7684\u6240\u6709.txt\u6587\u4ef6\n    txt_files = glob.glob(directory + '/*.txt')\n\n    # \u904d\u5386.txt\u6587\u4ef6\n    for txt_file in txt_files:\n        # \u6253\u5f00.txt\u6587\u4ef6\n        with open(txt_file, 'r') as f:\n            # \u8bfb\u53d6.txt\u6587\u4ef6\u4e2d\u7684\u6240\u6709\u884c\n            lines = f.readlines()\n\n        # \u904d\u5386\u6bcf\u4e00\u884c\n        for line in lines:\n            # \u5982\u679c\u884c\u5305\u542b'@'\uff0c\u5219\u6253\u5370\u8be5\u884c\n            if '@' in line:\n                print(line)\n\n        # \u5173\u95ed.txt\u6587\u4ef6\n        f.close()\n\n    # \u538b\u7f29\u76ee\u5f55\u4e2d\u7684\u6240\u6709.txt\u6587\u4ef6\n    with zipfile.ZipFile('textfiles.zip', 'w') as zipf:\n        for file in glob.glob(directory + '/*.txt'):\n            zipf.write(file)\n"}
{"task_id": "BigCodeBench/34", "solution": "import re\nfrom wordcloud import WordCloud\nimport matplotlib.pyplot as plt\n\n\ndef task_func(text):\n    \"\"\"\n    \n    \"\"\"\n    # \u53bb\u9664\u6807\u70b9\u7b26\u53f7\n    text = re.sub(r'[^\\w\\s]', '', text)\n    # \u53bb\u9664\u7a7a\u683c\n    text = re.sub(r'\\s+', '', text)\n    # \u8f6c\u6362\u4e3a\u5c0f\u5199\n    text = text.lower()\n    # \u53bb\u9664\u505c\u7528\u8bcd\n    stop_words = [\"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \"yourself\",\n                  \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\",\n                  \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\",\n                  \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\",\n                  \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\",\n                  \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \"through\", \"during\", \"before\",\n                  \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\",\n                  \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\",\n                  \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\",\n                  \"too\", \"very\", \"s"}
{"task_id": "BigCodeBench/37", "solution": "import pandas as pd\nfrom sklearn.ensemble import RandomForestClassifier\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n\ndef task_func(df, target_column):\n    \"\"\"\n    \n    \"\"\"\n    # \u6570\u636e\u9884\u5904\u7406\n    df = df.dropna()\n\n    # \u7279\u5f81\u9009\u62e9\n    X = df.drop(target_column, axis=1)\n    y = df[target_column]\n\n    # \u6a21\u578b\u8bad\u7ec3\n    model = RandomForestClassifier()\n    model.fit(X, y)\n\n    # \u7279\u5f81\u91cd\u8981\u6027\n    feature_importance = pd.DataFrame(model.feature_importances_,\n                                   index = X.columns,\n                                   columns=['importance']).sort_values('importance', ascending=False)\n\n    # \u7ed8\u5236\u7279\u5f81\u91cd\u8981\u6027\u56fe\n    plt.figure(figsize=(10,6))\n    sns.barplot(x=feature_importance.index, y=feature_importance['importance'])\n    plt.xlabel('Features')\n    plt.ylabel('Importance')\n    plt.title('Feature Importance')\n    plt.show()\n\n    return feature_importance\n"}
{"task_id": "BigCodeBench/82", "solution": "from flask import Flask, render_template, redirect, url_for\nfrom flask_login import LoginManager, UserMixin, login_user, login_required, logout_user, current_user\nfrom flask_wtf import FlaskForm\nfrom wtforms import StringField, PasswordField, SubmitField\nfrom wtforms.validators import DataRequired, Length\nfrom werkzeug.security import generate_password_hash, check_password_hash\n\nclass LoginForm(FlaskForm):\n    username = StringField('Username', validators=[DataRequired(), Length(min=4, max=25)])\n    password = PasswordField('Password', validators=[DataRequired(), Length(min=8, max=80)])\n    submit = SubmitField('Log In')\n\nlogin_manager = LoginManager()\n\ndef task_func(secret_key, template_folder):\n    \"\"\"\n    \n    \"\"\"\n    app = Flask(__name__, template_folder=template_folder)\n    app.config['SECRET_KEY'] = secret_key\n    login_manager = LoginManager()\n    login_manager.init_app(app)\n\n    @login_manager.user_loader\n    def load_user(user_id):\n        return User.query.get(int(user_id))\n\n    class User(UserMixin, db.Model):\n        id = db.Column(db.Integer, primary_key=True)\n        username = db.Column(db.String(20), unique=True, nullable=False)\n        password = db.Column(db.String(80), nullable=False)\n\n    @app.route('/')\n    def home():\n        return render_template('home.html')\n\n    @app.route('/login', methods=['GET', 'POST'])\n    def login():\n        form = LoginForm()\n        if form.validate_on_submit():\n            user = User.query.filter_by(username=form.username.data).first()\n            if user:\n                if check_password_hash(user.password, form.password.data):\n                    login_user(user, remember=True)"}
{"task_id": "BigCodeBench/89", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import stats\nfrom sklearn.preprocessing import StandardScaler\n\ndef task_func(data, column, outlier_z_score):\n    \"\"\"\n    \n    \"\"\"\n    # \u5bf9\u6570\u636e\u8fdb\u884c\u6807\u51c6\u5316\n    scaler = StandardScaler()\n    data_scaled = scaler.fit_transform(data)\n\n    # \u8ba1\u7b97z\u5206\u6570\n    z_scores = np.abs(stats.zscore(data_scaled))\n\n    # \u8bc6\u522b\u5f02\u5e38\u503c\n    outliers = np.where(z_scores > outlier_z_score)\n\n    # \u7ed8\u5236\u6570\u636e\n    plt.figure(figsize=(10, 6))\n    plt.scatter(data[:, 0], data[:, 1], c='blue', label='Normal data')\n    plt.scatter(data[outliers[0], 0], data[outliers[0], 1], c='red', label='Outliers')\n    plt.legend()\n    plt.show()\n\n    # \u8fd4\u56de\u5f02\u5e38\u503c\n    return data[outliers[0], :]\n"}
{"task_id": "BigCodeBench/92", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\nfrom matplotlib.collections import PathCollection\n\ndef task_func(data, n_clusters=3):\n    \"\"\"\n    \n    \"\"\"\n    kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(data)\n    data['cluster'] = kmeans.labels_\n    return data\n"}
{"task_id": "BigCodeBench/93", "solution": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\n\ndef task_func(data, n_components=2):\n    \"\"\"\n    \n    \"\"\"\n    pca = PCA(n_components=n_components)\n    pca.fit(data)\n    transformed_data = pca.transform(data)\n    return transformed_data\n"}
{"task_id": "BigCodeBench/99", "solution": "import matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nfrom sklearn.datasets import load_iris\n\ndef task_func():\n    \"\"\"\n    \n    \"\"\"\n    # \u52a0\u8f7d\u9e22\u5c3e\u82b1\u6570\u636e\u96c6\n    iris = load_iris()\n    df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n    df['target'] = iris.target\n\n    # \u7ed8\u5236\u6563\u70b9\u56fe\u77e9\u9635\n    sns.pairplot(df, hue='target')\n    plt.show()\n"}
{"task_id": "BigCodeBench/100", "solution": "import matplotlib.pyplot as plt\nimport pandas as pd\nimport random\nfrom datetime import datetime\n\ndef task_func(seed=42):\n    \"\"\"\n    \n    \"\"\"\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n\n    # \u52a0\u8f7d\u6570\u636e\n    data = pd.read_csv('data.csv')\n\n    # \u6570\u636e\u9884\u5904\u7406\n    data = data.dropna()\n    data['date'] = pd.to_datetime(data['date'])\n    data.set_index('date', inplace=True)\n\n    # \u5212\u5206\u8bad\u7ec3\u96c6\u548c\u6d4b\u8bd5\u96c6\n    train_data = data[:int(0.8 * len(data))]\n    test_data = data[int(0.8 * len(data)):]\n\n    # \u521b\u5efa\u6a21\u578b\n    model = LSTM(input_dim=1, output_dim=1, layers=1, window_size=1)\n\n    # \u8bad\u7ec3\u6a21\u578b\n    model.fit(train_data, epochs=100, batch_size=10, verbose=2)\n\n    # \u9884\u6d4b\n    predictions = model.predict(test_data)\n\n    # \u7ed8\u5236\u7ed3\u679c\n    plt.plot(test_data.index, test_data.values, label='actual')\n    plt.plot(test_data.index, predictions, label='prediction')\n    plt.legend()\n    plt.show()\n\n    # \u8bc4\u4f30\u6a21\u578b\n    mse = mean_squared_error(test_data.values, predictions)\n    rmse = sqrt(mse)\n    print(f'RMSE: {rmse}')\n\n    return rmse\n"}
{"task_id": "BigCodeBench/101", "solution": "import matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nimport numpy as np\n\ndef task_func(data_url=\"http://lib.stat.cmu.edu/datasets/boston\", seed=42):\n    \"\"\"\n    \n    \"\"\"\n    np.random.seed(seed)\n    boston = pd.read_csv(data_url)\n    return boston\n"}
{"task_id": "BigCodeBench/108", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom statsmodels.tsa.seasonal import seasonal_decompose\n\ndef task_func(df, freq='D', decomposition_model='multiplicative'):\n    \"\"\"\n    \n    \"\"\"\n    # \u5c06\u65e5\u671f\u5217\u8f6c\u6362\u4e3adatetime\u683c\u5f0f\n    df['date'] = pd.to_datetime(df['date'])\n\n    # \u6309\u65e5\u671f\u5bf9\u6570\u636e\u8fdb\u884c\u6392\u5e8f\n    df.sort_values('date', inplace=True)\n\n    # \u5c06\u65e5\u671f\u8bbe\u7f6e\u4e3a\u7d22\u5f15\n    df.set_index('date', inplace=True)\n\n    # \u5bf9\u6570\u636e\u8fdb\u884c\u5b63\u8282\u5206\u89e3\n    result = seasonal_decompose(df, model=decomposition_model, freq=freq)\n\n    # \u7ed8\u5236\u5206\u89e3\u56fe\n    result.plot()\n    plt.show()\n\n    return df\n"}
{"task_id": "BigCodeBench/120", "solution": "import pandas as pd\nfrom datetime import datetime, timedelta\nfrom random import randint, seed as random_seed\n\ndef task_func(start_date=datetime(2020, 1, 1), end_date=datetime(2020, 12, 31), seed=42):\n    \"\"\"\n    \n    \"\"\"\n    # \u8bbe\u7f6e\u968f\u673a\u6570\u751f\u6210\u5668\u7684\u79cd\u5b50\n    random_seed(seed)\n\n    # \u751f\u6210\u4e00\u4e2a\u968f\u673a\u65e5\u671f\u5217\u8868\n    dates = [start_date + timedelta(days=randint(0, (end_date - start_date).days)) for _ in range(100)]\n\n    # \u521b\u5efa\u4e00\u4e2a\u6570\u636e\u6846\n    df = pd.DataFrame(dates, columns=['date'])\n\n    # \u5c06\u65e5\u671f\u5217\u8f6c\u6362\u4e3a\u65e5\u671f\u65f6\u95f4\u683c\u5f0f\n    df['date'] = pd.to_datetime(df['date'])\n\n    # \u6309\u65e5\u671f\u5bf9\u6570\u636e\u6846\u8fdb\u884c\u6392\u5e8f\n    df.sort_values('date', inplace=True)\n\n    return df\n"}
{"task_id": "BigCodeBench/123", "solution": "import pandas as pd\nimport os\nimport glob\n\ndef task_func(my_list, file_dir='./data_files/', file_ext='.csv'):\n    \"\"\"\n    \n    \"\"\"\n    # \u521d\u59cb\u5316\u4e00\u4e2a\u7a7a\u7684pandas DataFrame\n    df = pd.DataFrame()\n\n    # \u904d\u5386\u5217\u8868\u4e2d\u7684\u6bcf\u4e2a\u6587\u4ef6\n    for file_name in my_list:\n        # \u68c0\u67e5\u6587\u4ef6\u662f\u5426\u5b58\u5728\n        if os.path.isfile(os.path.join(file_dir, file_name + file_ext)):\n            # \u5c06\u6587\u4ef6\u8bfb\u5165pandas DataFrame\n            temp_df = pd.read_csv(os.path.join(file_dir, file_name + file_ext))\n            # \u5c06temp_df\u8ffd\u52a0\u5230df\u4e2d\n            df = df.append(temp_df, ignore_index=True)\n        else:\n            print(f\"\u6587\u4ef6 {file_name} \u4e0d\u5b58\u5728\u3002\")\n\n    # \u8fd4\u56de\u5408\u5e76\u540e\u7684DataFrame\n    return df\n"}
{"task_id": "BigCodeBench/124", "solution": "from random import randint,seed as random_seed\nimport time\nimport matplotlib.pyplot as plt\n\ndef task_func(my_list, size=100, seed=100):\n    \"\"\"\n    \n    \"\"\"\n    random_seed(seed)\n    my_list.clear()\n    for i in range(size):\n        my_list.append(randint(1,100))\n    return my_list\n"}
{"task_id": "BigCodeBench/129", "solution": "import requests\nfrom bs4 import BeautifulSoup\nimport pandas as pd\n\ndef task_func(url='http://example.com'):\n    \"\"\"\n    \n    \"\"\"\n    # \u53d1\u9001HTTP\u8bf7\u6c42\n    response = requests.get(url)\n\n    # \u89e3\u6790HTML\u5185\u5bb9\n    soup = BeautifulSoup(response.text, 'html.parser')\n\n    # \u63d0\u53d6\u6240\u9700\u4fe1\u606f\n    # \u5047\u8bbe\u6240\u9700\u4fe1\u606f\u5728\u4e00\u4e2a\u8868\u683c\u4e2d\n    table = soup.find('table')\n\n    # \u5c06\u8868\u683c\u8f6c\u6362\u4e3apandas DataFrame\n    df = pd.read_html(str(table))[0]\n\n    return df\n"}
{"task_id": "BigCodeBench/139", "solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(df):\n    \"\"\"\n    \n    \"\"\"\n    # \u8ba1\u7b97\u6bcf\u4e2a\u7c7b\u522b\u7684\u5e73\u5747\u503c\n    mean_df = df.groupby('class').mean()\n\n    # \u8ba1\u7b97\u6bcf\u4e2a\u7c7b\u522b\u7684\u6807\u51c6\u5dee\n    std_df = df.groupby('class').std()\n\n    # \u8ba1\u7b97\u6bcf\u4e2a\u7c7b\u522b\u7684\u65b9\u5dee\n    var_df = df.groupby('class').var()\n\n    # \u8ba1\u7b97\u6bcf\u4e2a\u7c7b\u522b\u7684\u534f\u65b9\u5dee\n    cov_df = df.groupby('class').cov()\n\n    # \u8ba1\u7b97\u6bcf\u4e2a\u7c7b\u522b\u7684\u76f8\u5173\u7cfb\u6570\n    corr_df = df.groupby('class').corr()\n\n    return mean_df, std_df, var_df, cov_df, corr_df\n"}
{"task_id": "BigCodeBench/147", "solution": "import socket\nfrom ipaddress import IPv4Network\nfrom threading import Thread\n\ndef task_func(ip_range, port):\n    \"\"\"\n    \n    \"\"\"\n    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n        for ip in ip_range:\n            try:\n                s.connect((str(ip), port))\n                print(f\"Port {port} is open on {ip}\")\n            except socket.error:\n                pass\n"}
{"task_id": "BigCodeBench/161", "solution": "import re\nimport pandas as pd\nfrom datetime import datetime\n\n\ndef task_func(log_file):\n    \"\"\"\n    \n    \"\"\"\n    with open(log_file, 'r') as f:\n        data = f.read()\n\n    # \u63d0\u53d6\u65f6\u95f4\u6233\n    timestamps = re.findall(r'\\d{2}:\\d{2}:\\d{2} \\w+ \\w+ \\d{4}', data)\n\n    # \u8f6c\u6362\u4e3adatetime\u5bf9\u8c61\n    timestamps = [datetime.strptime(ts, '%H:%M:%S %b %d %Y') for ts in timestamps]\n\n    # \u6309\u65e5\u671f\u6392\u5e8f\n    timestamps.sort()\n\n    # \u8f6c\u6362\u4e3apandas dataframe\n    df = pd.DataFrame(timestamps, columns=['timestamp'])\n\n    # \u6309\u65e5\u671f\u5206\u7ec4\n    df['date'] = df['timestamp'].dt.date\n    df = df.groupby('date').count()\n\n    return df\n\n"}
{"task_id": "BigCodeBench/162", "solution": "import re\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n\ndef task_func(text, rwidth=0.8):\n    \"\"\"\n    \n    \"\"\"\n    # \u5c06\u6587\u672c\u5206\u5272\u6210\u5355\u8bcd\n    words = re.findall(r'\\b\\w+\\b', text)\n\n    # \u8ba1\u7b97\u6bcf\u4e2a\u5355\u8bcd\u7684\u9891\u7387\n    word_freq = {word: words.count(word) for word in words}\n\n    # \u8ba1\u7b97\u6bcf\u4e2a\u5355\u8bcd\u7684\u9891\u7387\u7684\u767e\u5206\u6bd4\n    word_freq_percent = {word: (freq / len(words)) * 100 for word, freq in word_freq.items()}\n\n    # \u7ed8\u5236\u5355\u8bcd\u9891\u7387\u7684\u6761\u5f62\u56fe\n    plt.bar(word_freq_percent.keys(), word_freq_percent.values(), width=rwidth)\n    plt.xlabel('\u5355\u8bcd')\n    plt.ylabel('\u9891\u7387\u767e\u5206\u6bd4')\n    plt.title('\u5355\u8bcd\u9891\u7387')\n    plt.show()\n\n"}
{"task_id": "BigCodeBench/177", "solution": "import re\nimport nltk\nfrom string import punctuation\n\n\ndef task_func(df):\n    \"\"\"\n    \n    \"\"\"\n    # 1. \u5220\u9664\u7f3a\u5931\u503c\n    df = df.dropna()\n\n    # 2. \u5220\u9664\u91cd\u590d\u9879\n    df = df.drop_duplicates()\n\n    # 3. \u5220\u9664\u6807\u70b9\u7b26\u53f7\n    df['text'] = df['text'].str.replace('[{}]'.format(re.escape(punctuation)), '')\n\n    # 4. \u5220\u9664\u505c\u7528\u8bcd\n    stop_words = nltk.corpus.stopwords.words('english')\n    df['text'] = df['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\n\n    # 5. \u8bcd\u5e72\u63d0\u53d6\n    stemmer = nltk.stem.PorterStemmer()\n    df['text'] = df['text'].apply(lambda x: ' '.join([stemmer.stem(word) for word in x.split()]))\n\n    # 6. \u8bcd\u5f62\u8fd8\u539f\n    lemmatizer = nltk.stem.WordNetLemmatizer()\n    df['text'] = df['text'].apply(lambda x: ' '.join([lemmatizer.lemmatize(word) for word in x.split()]))\n\n    return df\n"}
{"task_id": "BigCodeBench/184", "solution": "import pandas as pd\nimport re\nfrom sklearn.feature_extraction.text import CountVectorizer\n\n# Constants\nSTOPWORDS = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', 'yourself',\n             'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its', 'itself',\n             'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', 'these',\n             'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do',\n             'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while',\n             'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before',\n             'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again',\n             'further', 'then', 'once']\n\n\ndef task_func(dataframe, text_column):\n    \"\"\"\n    \n    \"\"\"\n    # Preprocessing\n    dataframe['text'] = dataframe[text_column].apply(lambda x: re.sub(r'\\W', ' ', str(x)))\n    dataframe['text'] = dataframe['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in STOPWORDS]))\n\n    # Vectorization\n    vectorizer = CountVectorizer(max_features=1000, min_df=5, max_df=0.7, stop_words=STOPWORDS)\n    dataframe['text'] = vectorizer.fit_transform(dataframe['text']).toarray()\n\n"}
{"task_id": "BigCodeBench/187", "solution": "import numpy as np\nimport geopandas as gpd\nfrom shapely.geometry import Point\n\ndef task_func(dic={'Lon': (-180, 180), 'Lat': (-90, 90)}, cities=['New York', 'London', 'Beijing', 'Tokyo', 'Sydney']):\n    \"\"\"\n    \n    \"\"\"\n    lon_range = dic['Lon']\n    lat_range = dic['Lat']\n\n    # Generate random points within the range\n    points = [Point(np.random.uniform(lon_range[0], lon_range[1]),\n                    np.random.uniform(lat_range[0], lat_range[1]))\n              for _ in range(1000)]\n\n    # Convert the list of points to a GeoDataFrame\n    gdf = gpd.GeoDataFrame(geometry=points)\n\n    # Add a column for city\n    gdf['city'] = cities\n\n    return gdf\n"}
{"task_id": "BigCodeBench/199", "solution": "import pandas as pd\nimport pytz\nfrom datetime import datetime\nfrom random import randint, seed as set_seed\n\ndef task_func(\n    utc_datetime,\n    cities=['New York', 'London', 'Beijing', 'Tokyo', 'Sydney'],\n    weather_conditions=['Sunny', 'Cloudy', 'Rainy', 'Snowy', 'Stormy'],\n    timezones={\n        'New York': 'America/New_York',\n        'London': 'Europe/London',\n        'Beijing': 'Asia/Shanghai',\n        'Tokyo': 'Asia/Tokyo',\n        'Sydney': 'Australia/Sydney'\n    },\n    seed=42\n):\n    \"\"\"\n    \n    \"\"\"\n    # \u8bbe\u7f6e\u968f\u673a\u79cd\u5b50\n    set_seed(seed)\n\n    # \u521b\u5efa\u4e00\u4e2a\u968f\u673a\u65e5\u671f\u548c\u65f6\u95f4\n    rand_date_time = utc_datetime + pd.Timedelta(hours=randint(0, 23), minutes=randint(0, 59))\n\n    # \u83b7\u53d6\u968f\u673a\u57ce\u5e02\u548c\u5929\u6c14\u6761\u4ef6\n    city = cities[randint(0, 4)]\n    weather = weather_conditions[randint(0, 4)]\n\n    # \u83b7\u53d6\u968f\u673a\u65f6\u533a\n    timezone = timezones[city]\n\n    # \u5c06\u968f\u673a\u65e5\u671f\u548c\u65f6\u95f4\u8f6c\u6362\u4e3a\u6307\u5b9a\u7684\u65f6\u533a\n    rand_date_time_in_timezone = rand_date_time.tz_localize(timezone)\n\n    return rand_date_time_in_timezone\n"}
{"task_id": "BigCodeBench/208", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\n\ndef task_func(elements, seed=0):\n    \"\"\"\n    \n    \"\"\"\n    np.random.seed(seed)\n    n = len(elements)\n    data = pd.DataFrame(np.random.rand(n, 2), columns=['x', 'y'])\n    data['z'] = np.random.rand(n)\n    data['w'] = np.random.rand(n)\n    data['v'] = np.random.rand(n)\n    data['u'] = np.random.rand(n)\n    data['t'] = np.random.rand(n)\n    data['s'] = np.random.rand(n)\n    data['r'] = np.random.rand(n)\n    data['q'] = np.random.rand(n)\n    data['p'] = np.random.rand(n)\n    data['o'] = np.random.rand(n)\n    data['n'] = np.random.rand(n)\n    data['m'] = np.random.rand(n)\n    data['l'] = np.random.rand(n)\n    data['k'] = np.random.rand(n)\n    data['j'] = np.random.rand(n)\n    data['i'] = np.random.rand(n)\n    data['h'] = np.random.rand(n)\n    data['g'] = np.random.rand(n)\n    data['f'] = np.random.rand(n)\n    data['e'] = np.random.rand(n)\n    data['d'] = np.random.rand(n)\n    data['c'] = np.random.rand(n)\n    data['b'] = np.random.rand(n)\n    data['a'] = np.random.rand(n)\n    return data\n\n"}
{"task_id": "BigCodeBench/211", "solution": "import requests\nimport os\nimport zipfile\n\ndef task_func(url, destination_directory, headers=None):\n    \"\"\"\n    \n    \"\"\"\n    if not os.path.exists(destination_directory):\n        os.makedirs(destination_directory)\n\n    response = requests.get(url, headers=headers)\n\n    with open(os.path.join(destination_directory, url.split(\"/\")[-1]), 'wb') as f:\n        f.write(response.content)\n\n    return os.path.join(destination_directory, url.split(\"/\")[-1])\n"}
{"task_id": "BigCodeBench/214", "solution": "import random\nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\n\ndef task_func(seed=42, image_size=(100, 100, 3), range_low=0, range_high=255):\n    \"\"\"\n    \n    \"\"\"\n    np.random.seed(seed)\n    image = np.random.randint(range_low, range_high, image_size, dtype=np.uint8)\n    return image\n"}
{"task_id": "BigCodeBench/227", "solution": "import numpy as np\nimport os\nimport soundfile as sf\nimport librosa\nimport matplotlib.pyplot as plt\n\ndef task_func(L, M, N, audio_file):\n    \"\"\"\n    \n    \"\"\"\n    # \u52a0\u8f7d\u97f3\u9891\u6587\u4ef6\n    data, samplerate = sf.read(audio_file)\n\n    # \u8ba1\u7b97\u97f3\u9891\u6587\u4ef6\u7684\u957f\u5ea6\n    length = len(data) / samplerate\n\n    # \u8ba1\u7b97\u97f3\u9891\u6587\u4ef6\u7684\u9891\u8c31\n    fft_data = np.abs(np.fft.fft(data))\n\n    # \u8ba1\u7b97\u9891\u8c31\u7684\u9891\u7387\n    freqs = np.fft.fftfreq(len(data), 1.0/samplerate)\n\n    # \u8ba1\u7b97\u9891\u8c31\u7684\u9891\u7387\u8303\u56f4\n    freq_range = np.linspace(0, 1, N)\n\n    # \u8ba1\u7b97\u9891\u8c31\u7684\u9891\u7387\u54cd\u5e94\n    freq_response = np.zeros(N)\n    for i in range(N):\n        freq_response[i] = np.sum(freqs[freqs >= freq_range[i]] * fft_data[freqs >= freq_range[i]])\n\n    # \u7ed8\u5236\u9891\u8c31\u7684\u9891\u7387\u54cd\u5e94\n    plt.figure(figsize=(10, 6))\n    plt.plot(freq_range, freq_response)\n    plt.xlabel('Frequency (Hz)')\n    plt.ylabel('Frequency Response')\n    plt.title('Frequency Response of the Audio File')\n    plt.grid(True)\n    plt.show()\n\n    # \u8ba1\u7b97\u9891\u8c31\u7684\u8c31\u56fe\n    spectrogram = librosa.stft(data)\n\n    # \u7ed8\u5236\u9891\u8c31\u7684\u8c31\u56fe\n    librosa.display.specshow(librosa.amplitude_to_db(np.abs(spectrogram), ref=np.max), y_axis='mel', fmax=M, x_axis='time')\n    plt.title('Spectrogram of the Audio File')\n    plt.show()"}
{"task_id": "BigCodeBench/239", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import stats\n\n\ndef task_func(original):\n    \"\"\"\n    \n    \"\"\"\n    # \u5c06\u539f\u59cb\u6570\u636e\u8f6c\u6362\u4e3anumpy\u6570\u7ec4\n    original_array = np.array(original)\n\n    # \u8ba1\u7b97\u539f\u59cb\u6570\u7ec4\u7684\u5747\u503c\n    mean = np.mean(original_array)\n\n    # \u8ba1\u7b97\u539f\u59cb\u6570\u7ec4\u7684\u6807\u51c6\u5dee\n    std_dev = np.std(original_array)\n\n    # \u8ba1\u7b97\u539f\u59cb\u6570\u7ec4\u7684\u6700\u5c0f\u503c\n    min_val = np.min(original_array)\n\n    # \u8ba1\u7b97\u539f\u59cb\u6570\u7ec4\u7684\u6700\u5927\u503c\n    max_val = np.max(original_array)\n\n    # \u8ba1\u7b97\u539f\u59cb\u6570\u7ec4\u7684\u56db\u5206\u4f4d\u6570\n    q1 = np.percentile(original_array, 25)\n    q3 = np.percentile(original_array, 75)\n\n    # \u8ba1\u7b97\u539f\u59cb\u6570\u7ec4\u7684\u4e2d\u4f4d\u6570\n    median = np.median(original_array)\n\n    # \u8ba1\u7b97\u539f\u59cb\u6570\u7ec4\u7684\u504f\u5ea6\n    skewness = stats.skew(original_array)\n\n    # \u8ba1\u7b97\u539f\u59cb\u6570\u7ec4\u7684\u5cf0\u5ea6\n    kurtosis = stats.kurtosis(original_array)\n\n    # \u8ba1\u7b97\u539f\u59cb\u6570\u7ec4\u7684\u6807\u51c6\u8bef\u5dee\n    std_error = np.std(original_array) / np.sqrt(len(original_array))\n\n    # \u8ba1\u7b97\u539f\u59cb\u6570\u7ec4\u7684\u65b9\u5dee\n    variance = np.var(original_array)\n\n    # \u8ba1\u7b97\u539f\u59cb\u6570\u7ec4\u7684\u534f\u65b9\u5dee\n    covariance = np.cov(original_array, original_array)[0][1]\n\n    # \u8ba1\u7b97\u539f\u59cb\u6570\u7ec4\u7684\u76f8\u5173\u7cfb\u6570\n    correlation = np.corrcoef(original_array, original_array)[0][1]\n\n    # \u8ba1\u7b97\u539f\u59cb\u6570\u7ec4\u7684\u56de\u5f52\u7cfb\u6570\n    slope, intercept, r_value, p_value, std_err = stats.linregress(original_array, original_array)\n\n    return {\n        '\u5747\u503c': mean,\n        '\u6807\u51c6\u5dee"}
{"task_id": "BigCodeBench/241", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn import preprocessing\n\n\ndef task_func(original):\n    \"\"\"\n    \n    \"\"\"\n    # \u5c06\u539f\u59cb\u6570\u636e\u8f6c\u6362\u4e3anumpy\u6570\u7ec4\n    data = np.array(original)\n\n    # \u5bf9\u6570\u636e\u8fdb\u884c\u5f52\u4e00\u5316\u5904\u7406\n    data_normalized = preprocessing.normalize(data, norm='l2')\n\n    # \u7ed8\u5236\u5f52\u4e00\u5316\u540e\u7684\u6570\u636e\n    plt.figure(figsize=(10, 5))\n    plt.plot(data_normalized)\n    plt.title('\u5f52\u4e00\u5316\u540e\u7684\u6570\u636e')\n    plt.xlabel('\u7d22\u5f15')\n    plt.ylabel('\u503c')\n    plt.show()\n\n"}
{"task_id": "BigCodeBench/267", "solution": "import numpy as np\nfrom scipy import fftpack\nimport matplotlib.pyplot as plt\n\n\ndef task_func(data, sample_rate=8000):\n    \"\"\"\n    \n    \"\"\"\n    # \u8ba1\u7b97FFT\n    fft_data = np.abs(fftpack.fft(data))\n    fft_data = fft_data[range(int(len(fft_data)/2))]\n\n    # \u8ba1\u7b97\u9891\u7387\n    freq = np.fft.fftfreq(len(data), 1/sample_rate)\n    freq = freq[range(int(len(freq)/2))]\n\n    # \u7ed8\u5236\u9891\u7387\u548cFFT\u6570\u636e\n    plt.figure(figsize=(10, 6))\n    plt.plot(freq, fft_data, 'b')\n    plt.title('FFT')\n    plt.xlabel('Frequency [Hz]')\n    plt.ylabel('|Y(freq)|')\n    plt.grid(True)\n    plt.show()\n\n    # \u8ba1\u7b97\u5cf0\u503c\n    peak_freq = freq[np.argmax(fft_data)]\n    print('\u5cf0\u503c\u9891\u7387:', peak_freq)\n\n    # \u8ba1\u7b97\u5cf0\u503c\u632f\u5e45\n    peak_amp = np.max(fft_data)\n    print('\u5cf0\u503c\u632f\u5e45:', peak_amp)\n\n    return peak_freq, peak_amp\n\n"}
{"task_id": "BigCodeBench/273", "solution": "import cgi\nimport http.server\nimport json\n\nSUCCESS_RESPONSE = {\n    'status': 'success',\n    'message': 'Data received successfully.'\n}\n\nERROR_RESPONSE = {\n    'status': 'error',\n    'message': 'Invalid data received.'\n}\n\ndef task_func():\n    \"\"\"\n    \n    \"\"\"\n    form = cgi.FieldStorage()\n    data = form.getvalue(\"data\")\n\n    try:\n        json_data = json.loads(data)\n    except json.JSONDecodeError:\n        return json.dumps(ERROR_RESPONSE)\n\n    # Here you can process the json_data\n\n    return json.dumps(SUCCESS_RESPONSE)\n"}
{"task_id": "BigCodeBench/274", "solution": "import cgi\nimport http.server\nimport smtplib\nfrom email.mime.text import MIMEText\nimport json\n\ndef task_func(smtp_server, smtp_port, smtp_username, smtp_password):\n    \"\"\"\n    \n    \"\"\"\n    # \u521b\u5efaSMTP\u670d\u52a1\u5668\n    server = smtplib.SMTP(smtp_server, smtp_port)\n    server.starttls()\n    server.login(smtp_username, smtp_password)\n\n    # \u8bfb\u53d6JSON\u6587\u4ef6\n    with open('data.json', 'r') as f:\n        data = json.load(f)\n\n    # \u521b\u5efa\u90ae\u4ef6\u5185\u5bb9\n    msg = MIMEText(data['message'])\n    msg['Subject'] = data['subject']\n    msg['From'] = smtp_username\n    msg['To'] = data['to']\n\n    # \u53d1\u9001\u90ae\u4ef6\n    server.sendmail(smtp_username, data['to'], msg.as_string())\n\n    server.quit()\n"}
{"task_id": "BigCodeBench/287", "solution": "from collections import Counter\nimport os\nimport json\n\ndef task_func(filename, directory):\n    \"\"\"\n    \n    \"\"\"\n    # \u68c0\u67e5\u6587\u4ef6\u662f\u5426\u5b58\u5728\n    if not os.path.isfile(os.path.join(directory, filename)):\n        print(f\"\u6587\u4ef6 {filename} \u4e0d\u5b58\u5728\u4e8e\u76ee\u5f55 {directory} \u4e2d\u3002\")\n        return\n\n    # \u8bfb\u53d6\u6587\u4ef6\n    with open(os.path.join(directory, filename), 'r') as f:\n        data = f.read()\n\n    # \u7edf\u8ba1\u5b57\u7b26\u9891\u7387\n    char_count = Counter(data)\n\n    # \u5c06\u5b57\u7b26\u9891\u7387\u8f6c\u6362\u4e3a\u5b57\u5178\n    char_dict = dict(char_count)\n\n    # \u5c06\u5b57\u5178\u8f6c\u6362\u4e3aJSON\n    json_data = json.dumps(char_dict)\n\n    # \u5c06JSON\u6570\u636e\u5199\u5165\u6587\u4ef6\n    with open(os.path.join(directory, f\"{filename}.json\"), 'w') as f:\n        f.write(json_data)\n\n    print(f\"\u6587\u4ef6 {filename} \u5df2\u6210\u529f\u8f6c\u6362\u4e3aJSON\u683c\u5f0f\u3002\")\n"}
{"task_id": "BigCodeBench/302", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Constants\nCOLUMNS = ['Date', 'Value']\n\ndef task_func(df, plot=False):\n    \"\"\"\n    \n    \"\"\"\n    # Calculate the mean of the 'Value' column\n    mean_value = df['Value'].mean()\n    print(f\"Mean value: {mean_value}\")\n\n    # Calculate the standard deviation of the 'Value' column\n    std_dev = df['Value'].std()\n    print(f\"Standard deviation: {std_dev}\")\n\n    # Create a new column 'Mean_Value'\n    df['Mean_Value'] = mean_value\n\n    # If plot is True, create a histogram of the 'Value' column\n    if plot:\n        plt.figure(figsize=(10, 6))\n        sns.histplot(df['Value'], bins=30, color='blue')\n        plt.title('Histogram of the \"Value\" column')\n        plt.show()\n\n    return df\n"}
{"task_id": "BigCodeBench/308", "solution": "import pandas as pd\nfrom statistics import mean\nimport random\n\n# Constants for generating the report data\nFIELDS = ['Physics', 'Math', 'Chemistry', 'Biology', 'English', 'History']\nSTUDENTS = ['Student_' + str(i) for i in range(1, 101)]\n\ndef task_func(additional_fields = []):\n    \"\"\"\n    \n    \"\"\"\n\n    Best student: {best_student} with average score: {best_student_avg}\n    Worst student: {worst_student} with average score: {worst_student_avg}\n    \"\"\"\n\n    return report\n"}
{"task_id": "BigCodeBench/310", "solution": "import os\nimport csv\nimport random\nfrom statistics import mean\n\n# Constants\nCOLUMNS = ['Name', 'Age', 'Height', 'Weight']\nPEOPLE_COUNT = 100\n\ndef task_func(filename):\n    \"\"\"\n    \n    \"\"\"\n    # Open the file\n    with open(filename, 'r') as file:\n        reader = csv.reader(file)\n        data = list(reader)\n\n    # Check if the file is empty\n    if len(data) == 0:\n        return \"File is empty\"\n\n    # Extract the data\n    people = []\n    for row in data:\n        people.append({COLUMNS[i]: row[i] for i in range(len(COLUMNS))})\n\n    # Calculate the mean of the age, height and weight\n    ages = [int(person['Age']) for person in people]\n    heights = [float(person['Height']) for person in people]\n    weights = [float(person['Weight']) for person in people]\n\n    mean_age = mean(ages)\n    mean_height = mean(heights)\n    mean_weight = mean(weights)\n\n    # Return the mean values\n    return mean_age, mean_height, mean_weight\n"}
{"task_id": "BigCodeBench/313", "solution": "import re\nimport os\nimport shutil\nfrom datetime import datetime\n\n\ndef task_func(directory):\n    \"\"\"\n    \n    \"\"\"\n    # \u68c0\u67e5\u76ee\u5f55\u662f\u5426\u5b58\u5728\n    if not os.path.exists(directory):\n        print(f\"\u76ee\u5f55 {directory} \u4e0d\u5b58\u5728\u3002\")\n        return\n\n    # \u83b7\u53d6\u76ee\u5f55\u4e2d\u7684\u6240\u6709\u6587\u4ef6\n    files = os.listdir(directory)\n\n    # \u904d\u5386\u6bcf\u4e2a\u6587\u4ef6\n    for file in files:\n        # \u83b7\u53d6\u6587\u4ef6\u7684\u5b8c\u6574\u8def\u5f84\n        file_path = os.path.join(directory, file)\n\n        # \u68c0\u67e5\u6587\u4ef6\u662f\u5426\u4e3a\u6587\u4ef6\n        if os.path.isfile(file_path):\n            # \u83b7\u53d6\u6587\u4ef6\u7684\u4fee\u6539\u65f6\u95f4\n            file_modified_time = os.path.getmtime(file_path)\n\n            # \u5c06\u4fee\u6539\u65f6\u95f4\u8f6c\u6362\u4e3adatetime\u5bf9\u8c61\n            file_modified_datetime = datetime.fromtimestamp(file_modified_time)\n\n            # \u83b7\u53d6\u5f53\u524d\u65f6\u95f4\n            current_datetime = datetime.now()\n\n            # \u8ba1\u7b97\u6587\u4ef6\u7684\u4fee\u6539\u65f6\u95f4\u4e0e\u5f53\u524d\u65f6\u95f4\u7684\u5dee\u503c\n            time_difference = current_datetime - file_modified_datetime\n\n            # \u5982\u679c\u6587\u4ef6\u7684\u4fee\u6539\u65f6\u95f4\u8d85\u8fc71\u5929\uff0c\u5219\u5220\u9664\u8be5\u6587\u4ef6\n            if time_difference.days > 1:\n                print(f\"\u6587\u4ef6 {file} \u5df2\u8d85\u8fc71\u5929\u672a\u4fee\u6539\uff0c\u5df2\u5220\u9664\u3002\")\n                os.remove(file_path)\n\n"}
{"task_id": "BigCodeBench/324", "solution": "import subprocess\nimport time\nimport threading\n\n\ndef task_func(file_list):\n    \"\"\"\n    \n    \"\"\"\n    for file_name in file_list:\n        print(f\"Processing {file_name}\")\n        time.sleep(1)  # simulate a long running task\n        print(f\"Finished processing {file_name}\")\n\n"}
{"task_id": "BigCodeBench/326", "solution": "import subprocess\nimport os\nimport sys\nimport glob\n\ndef task_func(directory_path):\n    \"\"\"\n    \n    \"\"\"\n    # \u83b7\u53d6\u76ee\u5f55\u4e2d\u7684\u6240\u6709\u6587\u4ef6\n    files = glob.glob(directory_path + '/*')\n\n    # \u904d\u5386\u6bcf\u4e2a\u6587\u4ef6\n    for file in files:\n        # \u68c0\u67e5\u6587\u4ef6\u662f\u5426\u4e3a\u76ee\u5f55\n        if os.path.isdir(file):\n            # \u9012\u5f52\u8c03\u7528\u51fd\u6570\n            task_func(file)\n        else:\n            # \u83b7\u53d6\u6587\u4ef6\u7684\u6269\u5c55\u540d\n            ext = os.path.splitext(file)[1]\n\n            # \u68c0\u67e5\u6587\u4ef6\u662f\u5426\u4e3aPython\u6587\u4ef6\n            if ext == '.py':\n                # \u4f7f\u7528subprocess\u8fd0\u884cPython\u6587\u4ef6\n                subprocess.run(['python', file])\n"}
{"task_id": "BigCodeBench/341", "solution": "import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndef task_func(df, col):\n    \"\"\"\n    \n    \"\"\"\n    # \u8ba1\u7b97\u5217\u7684\u5747\u503c\n    mean_val = df[col].mean()\n    \n    # \u8ba1\u7b97\u5217\u7684\u6807\u51c6\u5dee\n    std_val = df[col].std()\n    \n    # \u8ba1\u7b97\u5217\u7684\u6700\u5c0f\u503c\n    min_val = df[col].min()\n    \n    # \u8ba1\u7b97\u5217\u7684\u6700\u5927\u503c\n    max_val = df[col].max()\n    \n    # \u8ba1\u7b97\u5217\u7684\u56db\u5206\u4f4d\u6570\n    q1_val = df[col].quantile(0.25)\n    q3_val = df[col].quantile(0.75)\n    \n    # \u8ba1\u7b97\u5217\u7684\u4e2d\u4f4d\u6570\n    median_val = df[col].median()\n    \n    # \u8ba1\u7b97\u5217\u7684\u504f\u5ea6\n    skewness = df[col].skew()\n    \n    # \u8ba1\u7b97\u5217\u7684\u5cf0\u5ea6\n    kurtosis = df[col].kurt()\n    \n    # \u521b\u5efa\u4e00\u4e2a\u5b57\u5178\u6765\u4fdd\u5b58\u8ba1\u7b97\u7ed3\u679c\n    result = {\n        'mean': mean_val,\n        'std': std_val,\n        'min': min_val,\n        'max': max_val,\n        'q1': q1_val,\n        'q3': q3_val,\n        'median': median_val,\n        'skewness': skewness,\n        'kurtosis': kurtosis\n    }\n    \n    return result\n"}
{"task_id": "BigCodeBench/346", "solution": "import subprocess\nimport os\nimport sys\nimport time\n\n\ndef task_func(script_path, wait=True, *args):\n    \"\"\"\n    \n    \"\"\"\n    try:\n        # \u8fd0\u884c\u811a\u672c\n        process = subprocess.run([script_path] + list(args),\n                                 stdout=subprocess.PIPE,\n                                 stderr=subprocess.PIPE,\n                                 check=True)\n\n        # \u5982\u679c\u9700\u8981\u7b49\u5f85\u811a\u672c\u5b8c\u6210\n        if wait:\n            while process.poll() is None:\n                time.sleep(1)\n\n        # \u8fd4\u56de\u811a\u672c\u7684\u8f93\u51fa\n        return process.stdout.decode('utf-8')\n\n    except subprocess.CalledProcessError as e:\n        # \u5982\u679c\u811a\u672c\u5931\u8d25\uff0c\u6253\u5370\u9519\u8bef\u6d88\u606f\u5e76\u8fd4\u56de\n        print(f\"\u811a\u672c {script_path} \u5931\u8d25\uff1a\", file=sys.stderr)\n        print(e.output, file=sys.stderr)\n        return None\n\n"}
{"task_id": "BigCodeBench/360", "solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\n\ndef task_func(file_location, sheet_name):\n    \"\"\"\n    \n    \"\"\"\n    # \u8bfb\u53d6Excel\u6587\u4ef6\n    df = pd.read_excel(file_location, sheet_name=sheet_name)\n\n    # \u68c0\u67e5\u6570\u636e\u662f\u5426\u4e3a\u7a7a\n    if df.empty:\n        print(\"\u6570\u636e\u4e3a\u7a7a\")\n        return\n\n    # \u68c0\u67e5\u6570\u636e\u662f\u5426\u6709\u7f3a\u5931\u503c\n    if df.isnull().sum().sum() != 0:\n        print(\"\u6570\u636e\u4e2d\u5b58\u5728\u7f3a\u5931\u503c\")\n        return\n\n    # \u6570\u636e\u5206\u6790\n    # \u8ba1\u7b97\u6bcf\u4e2a\u7c7b\u522b\u7684\u6570\u91cf\n    category_counts = df['\u7c7b\u522b'].value_counts()\n\n    # \u7ed8\u5236\u67f1\u72b6\u56fe\n    plt.figure(figsize=(10,5))\n    plt.bar(category_counts.index, category_counts.values, alpha=0.8)\n    plt.title('\u7c7b\u522b\u6570\u91cf')\n    plt.xlabel('\u7c7b\u522b')\n    plt.ylabel('\u6570\u91cf')\n    plt.show()\n\n    # \u8ba1\u7b97\u6bcf\u4e2a\u7c7b\u522b\u7684\u5e73\u5747\u503c\n    category_means = df.groupby('\u7c7b\u522b')['\u503c'].mean()\n\n    # \u7ed8\u5236\u6761\u5f62\u56fe\n    plt.figure(figsize=(10,5))\n    plt.bar(category_means.index, category_means.values, alpha=0.8)\n    plt.title('\u7c7b\u522b\u5e73\u5747\u503c')\n    plt.xlabel('\u7c7b\u522b')\n    plt.ylabel('\u5e73\u5747\u503c')\n    plt.show()\n"}
{"task_id": "BigCodeBench/367", "solution": "from datetime import datetime\nfrom collections import defaultdict\nimport matplotlib.pyplot as plt\n\n\ndef task_func(activities):\n    \"\"\"\n    \n    \"\"\"\n    # \u521b\u5efa\u4e00\u4e2a\u5b57\u5178\u6765\u5b58\u50a8\u6bcf\u4e2a\u6d3b\u52a8\u7684\u5f00\u59cb\u548c\u7ed3\u675f\u65f6\u95f4\n    activity_dict = defaultdict(list)\n\n    for activity in activities:\n        start_time, end_time = map(int, activity.split('-'))\n        activity_dict[activity[0]].append((start_time, end_time))\n\n    # \u5bf9\u6bcf\u4e2a\u6d3b\u52a8\u8fdb\u884c\u6392\u5e8f\n    for activity in activity_dict:\n        activity_dict[activity].sort(key=lambda x: x[0])\n\n    # \u8ba1\u7b97\u6d3b\u52a8\u7684\u603b\u65f6\u95f4\n    total_time = 0\n    for activity in activity_dict:\n        total_time += max(x[1] for x in activity_dict[activity]) - min(x[0] for x in activity_dict[activity])\n\n    return total_time\n\n"}
{"task_id": "BigCodeBench/368", "solution": "import os\nimport shutil\nimport random\n\n\ndef task_func(src_dir: str, dest_dir: str, seed:int = 100) -> str:\n    \"\"\"\n    \n    \"\"\"\n    # \u8bbe\u7f6e\u968f\u673a\u79cd\u5b50\n    random.seed(seed)\n\n    # \u68c0\u67e5\u6e90\u76ee\u5f55\u662f\u5426\u5b58\u5728\n    if not os.path.exists(src_dir):\n        raise FileNotFoundError(f\"\u6e90\u76ee\u5f55 {src_dir} \u4e0d\u5b58\u5728\")\n\n    # \u68c0\u67e5\u76ee\u6807\u76ee\u5f55\u662f\u5426\u5b58\u5728\n    if os.path.exists(dest_dir):\n        shutil.rmtree(dest_dir)\n\n    # \u590d\u5236\u6587\u4ef6\n    shutil.copytree(src_dir, dest_dir)\n\n    return dest_dir\n"}
{"task_id": "BigCodeBench/374", "solution": "import regex as re\nimport glob\nimport os\nfrom openpyxl import load_workbook\n\n\ndef task_func(directory_path='./xlsx_files/'):\n    \"\"\"\n    \n    \"\"\"\n    # \u83b7\u53d6\u76ee\u5f55\u4e2d\u6240\u6709.xlsx\u6587\u4ef6\u7684\u5217\u8868\n    xlsx_files = glob.glob(directory_path + '*.xlsx')\n\n    for file in xlsx_files:\n        # \u52a0\u8f7dExcel\u6587\u4ef6\n        wb = load_workbook(filename=file)\n\n        # \u83b7\u53d6\u6240\u6709\u5de5\u4f5c\u8868\u7684\u540d\u79f0\n        sheet_names = wb.sheetnames\n\n        for sheet_name in sheet_names:\n            sheet = wb[sheet_name]\n\n            # \u904d\u5386\u5de5\u4f5c\u8868\u4e2d\u7684\u6bcf\u4e00\u884c\n            for row in sheet.iter_rows():\n                # \u904d\u5386\u6bcf\u4e00\u884c\u4e2d\u7684\u6bcf\u4e2a\u5355\u5143\u683c\n                for cell in row:\n                    # \u68c0\u67e5\u5355\u5143\u683c\u662f\u5426\u5305\u542b\u6570\u5b57\n                    if re.match(r'\\d+', str(cell.value)):\n                        # \u5982\u679c\u5355\u5143\u683c\u5305\u542b\u6570\u5b57\uff0c\u5219\u5c06\u5176\u66ff\u6362\u4e3a'NUMBER'\n                        sheet[cell.coordinate] = 'NUMBER'\n\n            # \u4fdd\u5b58\u4fee\u6539\u540e\u7684\u5de5\u4f5c\u8868\n            wb.save(file)\n\n"}
{"task_id": "BigCodeBench/399", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nimport math\n\n\ndef task_func(frequency, sample_size=10000):\n    \"\"\"\n    \n    \"\"\"\n    # Generate random data\n    data = np.random.normal(0, 1, sample_size)\n\n    # Calculate mean and standard deviation\n    mean = np.mean(data)\n    std_dev = np.std(data)\n\n    # Calculate the frequency of the data\n    freq_data = np.histogram(data, bins=100, density=True)[0]\n\n    # Calculate the cumulative distribution function\n    cdf = np.cumsum(freq_data)\n\n    # Calculate the quantiles\n    quantiles = np.arange(0, 1, 1/frequency)\n\n    # Plot the histogram\n    plt.figure(figsize=(10, 6))\n    plt.plot(data, label='Data')\n    plt.plot(mean + quantiles * std_dev, label='Mean + ' + str(frequency) + ' * std_dev')\n    plt.plot(mean - quantiles * std_dev, label='Mean - ' + str(frequency) + ' * std_dev')\n    plt.legend()\n    plt.show()\n\n    # Plot the cumulative distribution function\n    plt.figure(figsize=(10, 6))\n    plt.plot(quantiles, cdf, label='CDF')\n    plt.legend()\n    plt.show()\n\n"}
{"task_id": "BigCodeBench/401", "solution": "from flask import Flask\nimport os\nfrom flask_mail import Mail\n\ndef task_func(app_name):\n    \"\"\"\n    \n    \"\"\"\n    app = Flask(app_name)\n    mail = Mail(app)\n\n    return app, mail\n"}
{"task_id": "BigCodeBench/409", "solution": "import os\nimport pandas as pd\nimport numpy as np\n\ndef task_func(excel_file_path, file_name, column_name):\n    \"\"\"\n    \n    \"\"\"\n    # \u8bfb\u53d6Excel\u6587\u4ef6\n    df = pd.read_excel(excel_file_path + file_name, engine='openpyxl')\n\n    # \u68c0\u67e5\u5217\u540d\u662f\u5426\u5b58\u5728\n    if column_name not in df.columns:\n        print(f\"\u9519\u8bef\uff1a{column_name} \u4e0d\u5b58\u5728\u4e8e\u6570\u636e\u96c6\u4e2d\u3002\")\n        return\n\n    # \u8ba1\u7b97\u5217\u7684\u5747\u503c\n    mean_value = df[column_name].mean()\n\n    # \u8ba1\u7b97\u5217\u7684\u6807\u51c6\u5dee\n    std_dev = df[column_name].std()\n\n    # \u521b\u5efa\u4e00\u4e2a\u65b0\u7684DataFrame\n    new_df = pd.DataFrame({\n        '\u5217\u540d': [column_name],\n        '\u5747\u503c': [mean_value],\n        '\u6807\u51c6\u5dee': [std_dev]\n    })\n\n    # \u5c06\u65b0\u7684DataFrame\u8ffd\u52a0\u5230\u539f\u59cbDataFrame\u4e2d\n    df = df.append(new_df, ignore_index=True)\n\n    # \u5c06DataFrame\u4fdd\u5b58\u4e3a\u65b0\u7684Excel\u6587\u4ef6\n    df.to_excel(excel_file_path + 'new_' + file_name, index=False)\n\n    print(f\"\u5747\u503c\uff1a{mean_value}\")\n    print(f\"\u6807\u51c6\u5dee\uff1a{std_dev}\")\n"}
{"task_id": "BigCodeBench/417", "solution": "from sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.optimizers import SGD\n\ndef task_func(X, Y):\n    \"\"\"\n    \n    \"\"\"\n    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n\n    model = Sequential()\n    model.add(Dense(10, input_dim=X_train.shape[1], activation='relu'))\n    model.add(Dense(1, activation='sigmoid'))\n\n    sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n\n    model.compile(optimizer=sgd, loss='binary_crossentropy')\n\n    history = model.fit(X_train, Y_train, epochs=20, batch_size=10, verbose=1, validation_data=(X_test, Y_test))\n\n    score, acc = model.evaluate(X_test, Y_test, verbose=0)\n    print('Test score:', score)\n    print('Test accuracy:', acc)\n\n    plt.figure(figsize=(12, 6))\n    plt.subplot(1, 2, 1)\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title('Model Loss')\n    plt.ylabel('Loss')\n    plt.xlabel('Epoch')\n    plt.legend(['Train', 'Test'], loc='upper right')\n\n    plt.subplot(1, 2, 2)\n    plt.plot(history.history['acc'])\n    plt.plot(history.history['val_acc'])\n    plt.title('Model Accuracy')\n    plt.ylabel('Accuracy')\n    plt"}
{"task_id": "BigCodeBench/418", "solution": "from tensorflow import keras\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_curve, auc\nimport matplotlib.pyplot as plt\n\ndef task_func(X, Y):\n    \"\"\"\n    \n    \"\"\"\n    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n\n    model = keras.models.Sequential()\n    model.add(keras.layers.Dense(128, input_dim=X_train.shape[1], activation='relu'))\n    model.add(keras.layers.Dense(64, activation='relu'))\n    model.add(keras.layers.Dense(1, activation='sigmoid'))\n\n    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n\n    model.fit(X_train, Y_train, epochs=10, batch_size=32)\n\n    Y_pred = model.predict(X_test)\n\n    fpr, tpr, _ = roc_curve(Y_test, Y_pred)\n    roc_auc = auc(fpr, tpr)\n\n    plt.figure()\n    plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver Operating Characteristic')\n    plt.legend(loc=\"lower right\")\n    plt.show()\n\n    return model\n\n"}
{"task_id": "BigCodeBench/424", "solution": "import cv2\nimport numpy as np\nimport os\nfrom sklearn.cluster import KMeans\n\ndef task_func(image_path='image.jpg', n_clusters=3, random_seed=42):\n    \"\"\"\n    \n    \"\"\"\n    # \u52a0\u8f7d\u56fe\u50cf\n    image = cv2.imread(image_path)\n\n    # \u5c06\u56fe\u50cf\u8f6c\u6362\u4e3a\u7070\u5ea6\u56fe\u50cf\n    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n\n    # \u4f7f\u7528KMeans\u805a\u7c7b\n    kmeans = KMeans(n_clusters=n_clusters, random_state=random_seed)\n    labels = kmeans.fit_predict(gray)\n\n    # \u5c06\u805a\u7c7b\u6807\u7b7e\u5e94\u7528\u4e8e\u539f\u59cb\u56fe\u50cf\n    result = np.zeros_like(image)\n    result[labels.ravel()] = image[labels.ravel()]\n\n    # \u663e\u793a\u7ed3\u679c\n    cv2.imshow('Result', result)\n    cv2.waitKey(0)\n    cv2.destroyAllWindows()\n\n    return result\n"}
{"task_id": "BigCodeBench/443", "solution": "import numpy as np\nfrom sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\n\n\ndef task_func(\n    P: np.ndarray,\n    T: np.ndarray,\n    n_clusters: int = 3,\n    random_state: int = 0,\n    n_init: int = 10,\n) -> (np.ndarray, plt.Axes):\n    \"\"\"\n    \n    \"\"\"\n    kmeans = KMeans(\n        n_clusters=n_clusters,\n        random_state=random_state,\n        n_init=n_init,\n    )\n\n    kmeans.fit(P)\n\n    labels = kmeans.labels_\n\n    fig, ax = plt.subplots()\n\n    scatter = ax.scatter(\n        P[:, 0],\n        P[:, 1],\n        c=labels,\n        cmap='viridis'\n    )\n\n    centroids = kmeans.cluster_centers_\n    ax.scatter(\n        centroids[:, 0],\n        centroids[:, 1],\n        c='red',\n        marker='X'\n    )\n\n    plt.colorbar(scatter)\n    plt.title('K-means clustering')\n    plt.xlabel('P[0]')\n    plt.ylabel('P[1]')\n\n    return labels, ax\n\n"}
{"task_id": "BigCodeBench/445", "solution": "import numpy as np\nfrom scipy.spatial import Voronoi, voronoi_plot_2d\nimport matplotlib.pyplot as plt\n\n\ndef task_func(points, seed=0):\n    \"\"\"\n    \n    \"\"\"\n    np.random.seed(seed)\n    n = len(points)\n    if n < 3:\n        raise ValueError(\"At least 3 points are required\")\n\n    # Generate a random Voronoi diagram\n    vor = Voronoi(points)\n\n    # Compute the Voronoi diagram\n    fig, ax = plt.subplots()\n    voronoi_plot_2d(vor, ax=ax)\n\n    # Plot the points\n    ax.scatter(points[:, 0], points[:, 1], c='r', s=50)\n\n    plt.show()\n\n"}
{"task_id": "BigCodeBench/454", "solution": "import os\nimport shutil\nimport glob\n\n\ndef task_func(src_dir, dest_dir, ext):\n    \"\"\"\n    \n    \"\"\"\n    # \u68c0\u67e5\u6e90\u76ee\u5f55\u662f\u5426\u5b58\u5728\n    if not os.path.exists(src_dir):\n        print(f\"\u6e90\u76ee\u5f55 {src_dir} \u4e0d\u5b58\u5728\u3002\")\n        return\n\n    # \u68c0\u67e5\u76ee\u6807\u76ee\u5f55\u662f\u5426\u5b58\u5728\n    if not os.path.exists(dest_dir):\n        print(f\"\u76ee\u6807\u76ee\u5f55 {dest_dir} \u4e0d\u5b58\u5728\u3002\")\n        return\n\n    # \u83b7\u53d6\u6e90\u76ee\u5f55\u4e2d\u7684\u6240\u6709\u6587\u4ef6\n    files = glob.glob(f\"{src_dir}/*.{ext}\")\n\n    # \u904d\u5386\u6587\u4ef6\n    for file in files:\n        # \u83b7\u53d6\u6587\u4ef6\u540d\n        file_name = os.path.basename(file)\n\n        # \u5c06\u6587\u4ef6\u590d\u5236\u5230\u76ee\u6807\u76ee\u5f55\n        shutil.copy(file, dest_dir)\n\n        # \u6253\u5370\u590d\u5236\u7684\u6587\u4ef6\u540d\n        print(f\"\u5df2\u590d\u5236 {file_name} \u5230 {dest_dir}\")\n\n"}
{"task_id": "BigCodeBench/458", "solution": "import json\nimport re\nimport pandas as pd\n\n\ndef task_func(json_str):\n    \"\"\"\n    \n    \"\"\"\n    # \u5c06json\u5b57\u7b26\u4e32\u8f6c\u6362\u4e3a\u5b57\u5178\n    data = json.loads(json_str)\n\n    # \u521b\u5efa\u4e00\u4e2a\u7a7a\u7684pandas DataFrame\n    df = pd.DataFrame()\n\n    # \u904d\u5386\u5b57\u5178\u4e2d\u7684\u6bcf\u4e2a\u952e\u503c\u5bf9\n    for key, value in data.items():\n        # \u5982\u679c\u503c\u662f\u5217\u8868\uff0c\u5219\u5c06\u5176\u8f6c\u6362\u4e3aDataFrame\n        if isinstance(value, list):\n            df[key] = pd.DataFrame(value)\n        # \u5982\u679c\u503c\u662f\u5b57\u5178\uff0c\u5219\u5c06\u5176\u8f6c\u6362\u4e3aDataFrame\n        elif isinstance(value, dict):\n            df[key] = pd.DataFrame([value])\n        # \u5982\u679c\u503c\u662f\u5b57\u7b26\u4e32\uff0c\u5219\u4f7f\u7528\u6b63\u5219\u8868\u8fbe\u5f0f\u63d0\u53d6\u51fa\u6570\u5b57\n        elif isinstance(value, str):\n            numbers = re.findall(r'\\d+\\.?\\d*', value)\n            df[key] = pd.DataFrame(numbers, columns=[key])\n\n    return df\n\n"}
{"task_id": "BigCodeBench/461", "solution": "import subprocess\nimport psutil\nimport time\nimport os\n\n\ndef task_func(script_path: str, timeout=10) -> dict:\n    \"\"\"\n    \n    \"\"\"\n    # \u521b\u5efa\u5b50\u8fdb\u7a0b\n    p = subprocess.Popen(script_path, stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True)\n\n    # \u5f00\u59cb\u8ba1\u65f6\n    start_time = time.time()\n\n    # \u7b49\u5f85\u5b50\u8fdb\u7a0b\u7ed3\u675f\n    while True:\n        if p.poll() is not None:\n            break\n        if time.time() - start_time > timeout:\n            raise TimeoutError(f\"\u811a\u672c {script_path} \u5728 {timeout} \u79d2\u5185\u672a\u5b8c\u6210\")\n        time.sleep(1)\n\n    # \u8bfb\u53d6\u5b50\u8fdb\u7a0b\u7684\u8f93\u51fa\n    stdout = p.stdout.read().decode()\n    stderr = p.stderr.read().decode()\n\n    # \u8fd4\u56de\u7ed3\u679c\n    return {\"stdout\": stdout, \"stderr\": stderr}\n\n"}
{"task_id": "BigCodeBench/477", "solution": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n\ndef task_func(N=100, CATEGORIES=[\"A\", \"B\", \"C\", \"D\", \"E\"], seed=42):\n    \"\"\"\n    \n    \"\"\"\n    np.random.seed(seed)\n    df = pd.DataFrame()\n    df['category'] = np.random.choice(CATEGORIES, N)\n    df['value'] = np.random.normal(loc=10, scale=1, size=N)\n    return df\n\n"}
{"task_id": "BigCodeBench/486", "solution": "from datetime import datetime\nimport pandas as pd\nimport numpy as np\n\n\ndef task_func(start_time, end_time, step, trend, seed=42):\n    \"\"\"\n    \n    \"\"\"\n    np.random.seed(seed)\n    np.random.randn(1)\n\n    # \u751f\u6210\u4e00\u4e2a\u968f\u673a\u6570\n    random_num = np.random.randn(1)\n\n    # \u751f\u6210\u4e00\u4e2a\u968f\u673a\u65e5\u671f\n    random_date = start_time + pd.DateOffset(np.random.randint(low=0, high=(end_time - start_time).days, dtype='timedelta64[D]'))\n\n    # \u751f\u6210\u4e00\u4e2a\u968f\u673a\u8d8b\u52bf\n    trend_value = trend * random_num\n\n    # \u751f\u6210\u4e00\u4e2a\u968f\u673a\u503c\n    random_value = random_date + trend_value\n\n    return random_value\n\n"}
{"task_id": "BigCodeBench/492", "solution": "import pandas as pd\nfrom datetime import datetime\nimport random\n\n\ndef task_func(\n    epoch_milliseconds,\n    random_seed=0,\n    products=[\"Product1\", \"Product2\", \"Product3\", \"Product4\", \"Product5\"],\n):\n    \"\"\"\n    \n    \"\"\"\n    # \u8bbe\u7f6e\u968f\u673a\u79cd\u5b50\n    random.seed(random_seed)\n\n    # \u521b\u5efa\u4e00\u4e2a\u65f6\u95f4\u6233\u5217\u8868\n    timestamps = [\n        datetime.fromtimestamp(epoch_milliseconds / 1000.0)\n        for epoch_milliseconds in epoch_milliseconds\n    ]\n\n    # \u521b\u5efa\u4e00\u4e2a\u968f\u673a\u6570\u5217\u8868\n    random_numbers = [random.random() for _ in range(len(timestamps))]\n\n    # \u521b\u5efa\u4e00\u4e2a\u968f\u673a\u4ea7\u54c1\u5217\u8868\n    random_products = [\n        random.choice(products) for _ in range(len(timestamps))\n    ]\n\n    # \u521b\u5efa\u4e00\u4e2a\u6570\u636e\u6846\n    df = pd.DataFrame(\n        {\n            \"Timestamp\": timestamps,\n            \"RandomNumber\": random_numbers,\n            \"RandomProduct\": random_products,\n        }\n    )\n\n    return df\n\n"}
{"task_id": "BigCodeBench/501", "solution": "import xlwt\nimport os\nimport pandas as pd\n\ndef task_func(json_str, filename, sheet_name=\"sheet1\"):\n    \"\"\"\n    \n    \"\"\"\n    # \u5c06json\u5b57\u7b26\u4e32\u8f6c\u6362\u4e3apandas dataframe\n    df = pd.read_json(json_str)\n\n    # \u5c06dataframe\u4fdd\u5b58\u4e3axlsx\u6587\u4ef6\n    df.to_excel(filename, sheet_name=sheet_name, index=False)\n\n    # \u6253\u5370\u6587\u4ef6\u8def\u5f84\n    print(f\"\u6587\u4ef6\u4fdd\u5b58\u5728\uff1a{os.path.abspath(filename)}\")\n"}
{"task_id": "BigCodeBench/502", "solution": "from datetime import datetime, timedelta\nimport pandas as pd\nimport random\nimport seaborn as sns\n\n\ndef task_func(days_in_past=7, random_seed=0):\n    \"\"\"\n    \n    \"\"\"\n    # \u8bbe\u7f6e\u968f\u673a\u79cd\u5b50\u4ee5\u4fbf\u91cd\u73b0\u7ed3\u679c\n    random.seed(random_seed)\n\n    # \u751f\u6210\u4e00\u4e2a\u65e5\u671f\u8303\u56f4\n    date_range = pd.date_range(start=datetime.now() - timedelta(days=days_in_past), end=datetime.now())\n\n    # \u751f\u6210\u4e00\u4e2a\u968f\u673a\u6570\u636e\u6846\n    df = pd.DataFrame(\n        {\n            \"date\": date_range,\n            \"value\": random.choices(range(1, 100), k=len(date_range))\n        }\n    )\n\n    # \u5c06\u65e5\u671f\u8f6c\u6362\u4e3a\u65f6\u95f4\u6233\n    df[\"date\"] = df[\"date\"].apply(lambda x: x.timestamp())\n\n    # \u5c06\u6570\u636e\u6846\u8f6c\u6362\u4e3a\u65f6\u95f4\u5e8f\u5217\n    df_ts = df.set_index(\"date\").sort_index()\n\n    # \u7ed8\u5236\u65f6\u95f4\u5e8f\u5217\u56fe\n    sns.set(style=\"whitegrid\")\n    sns.lineplot(data=df_ts)\n\n    return df_ts\n\n"}
{"task_id": "BigCodeBench/503", "solution": "import numpy as np\nimport pandas as pd\nfrom datetime import datetime\n\n\ndef task_func(\n    days_in_past=7, stock_names=[\"AAPL\", \"GOOGL\", \"MSFT\", \"AMZN\", \"FB\"], random_seed=0\n):\n    \"\"\"\n    \n    \"\"\"\n    np.random.seed(random_seed)\n\n    # Generate random data\n    data = {\n        stock: np.random.normal(loc=0.001, scale=0.05, size=(100,)) for stock in stock_names\n    }\n\n    # Create a dataframe\n    df = pd.DataFrame(data)\n\n    # Add a date index\n    df.index = pd.date_range(start=datetime.now() - pd.Timedelta(days=days_in_past), periods=100)\n\n    # Add a column for the stock names\n    df[\"Stock\"] = stock_names\n\n    return df\n\n"}
{"task_id": "BigCodeBench/509", "solution": "import pandas as pd\nimport csv\nfrom difflib import ndiff\n\n\ndef task_func(file_path1, file_path2, delimiter=',', quotechar='\"'):\n    \"\"\"\n    \n    \"\"\"\n    df1 = pd.read_csv(file_path1, delimiter=delimiter, quotechar=quotechar)\n    df2 = pd.read_csv(file_path2, delimiter=delimiter, quotechar=quotechar)\n\n    # \u68c0\u67e5\u5217\u540d\u662f\u5426\u76f8\u540c\n    if not set(df1.columns).issubset(df2.columns):\n        print(\"\u5217\u540d\u4e0d\u5339\u914d\u3002\")\n        return\n\n    # \u68c0\u67e5\u5217\u6570\u636e\u7c7b\u578b\u662f\u5426\u76f8\u540c\n    for col in df1.columns:\n        if not df1[col].dtype == df2[col].dtype:\n            print(f\"\u5217 {col} \u7684\u6570\u636e\u7c7b\u578b\u4e0d\u5339\u914d\u3002\")\n            return\n\n    # \u68c0\u67e5\u5217\u6570\u636e\u662f\u5426\u76f8\u540c\n    for col in df1.columns:\n        if not set(df1[col]) == set(df2[col]):\n            print(f\"\u5217 {col} \u7684\u6570\u636e\u4e0d\u5339\u914d\u3002\")\n            return\n\n    # \u68c0\u67e5\u884c\u6570\u636e\u662f\u5426\u76f8\u540c\n    if not df1.equals(df2):\n        print(\"\u884c\u6570\u636e\u4e0d\u5339\u914d\u3002\")\n        return\n\n    print(\"\u6587\u4ef6\u5185\u5bb9\u5b8c\u5168\u76f8\u540c\u3002\")\n\n"}
{"task_id": "BigCodeBench/511", "solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\ndef task_func(column, data):\n    \"\"\"\n    \n    \"\"\"\n    # \u8ba1\u7b97\u5217\u7684\u5747\u503c\n    mean = np.mean(data[column])\n\n    # \u8ba1\u7b97\u5217\u7684\u6807\u51c6\u5dee\n    std_dev = np.std(data[column])\n\n    # \u8ba1\u7b97\u5217\u7684\u65b9\u5dee\n    var = np.var(data[column])\n\n    # \u8ba1\u7b97\u5217\u7684\u6807\u51c6\u8bef\u5dee\n    std_error = np.sqrt(var / len(data[column]))\n\n    # \u8ba1\u7b97\u5217\u7684\u7f6e\u4fe1\u533a\u95f4\n    lower_bound = mean - 1.96 * std_error\n    upper_bound = mean + 1.96 * std_error\n\n    return mean, std_dev, var, std_error, lower_bound, upper_bound\n\n"}
{"task_id": "BigCodeBench/513", "solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\ndef task_func(column, data):\n    \"\"\"\n    \n    \"\"\"\n    # \u8ba1\u7b97\u5217\u7684\u5747\u503c\n    mean = np.mean(data[column])\n\n    # \u8ba1\u7b97\u5217\u7684\u6807\u51c6\u5dee\n    std_dev = np.std(data[column])\n\n    # \u8ba1\u7b97\u5217\u7684\u65b9\u5dee\n    var = np.var(data[column])\n\n    # \u8ba1\u7b97\u5217\u7684\u6807\u51c6\u8bef\u5dee\n    std_error = np.sqrt(var / len(data[column]))\n\n    # \u8ba1\u7b97\u5217\u7684\u7f6e\u4fe1\u533a\u95f4\n    lower_bound = mean - 1.96 * std_error\n    upper_bound = mean + 1.96 * std_error\n\n    return mean, std_dev, var, std_error, lower_bound, upper_bound\n\n"}
{"task_id": "BigCodeBench/526", "solution": "import json\nimport pandas as pd\nimport numpy as np\nfrom collections import defaultdict\n\n\ndef task_func(input_file=\"data.json\"):\n    \"\"\"\n    \n    \"\"\"\n    with open(input_file, 'r') as f:\n        data = json.load(f)\n\n    # \u5c06\u6570\u636e\u8f6c\u6362\u4e3apandas dataframe\n    df = pd.DataFrame(data)\n\n    # \u8ba1\u7b97\u6bcf\u4e2a\u5b57\u6bb5\u7684\u9891\u7387\n    field_freq = defaultdict(int)\n    for field in df.columns:\n        for i in df[field]:\n            field_freq[field] += i\n\n    # \u8ba1\u7b97\u6bcf\u4e2a\u5b57\u6bb5\u7684\u5e73\u5747\u503c\n    field_avg = defaultdict(float)\n    for field in df.columns:\n        field_avg[field] = np.mean(df[field].values)\n\n    # \u8ba1\u7b97\u6bcf\u4e2a\u5b57\u6bb5\u7684\u6807\u51c6\u5dee\n    field_std = defaultdict(float)\n    for field in df.columns:\n        field_std[field] = np.std(df[field].values)\n\n    # \u8ba1\u7b97\u6bcf\u4e2a\u5b57\u6bb5\u7684\u6700\u5c0f\u503c\n    field_min = defaultdict(float)\n    for field in df.columns:\n        field_min[field] = np.min(df[field].values)\n\n    # \u8ba1\u7b97\u6bcf\u4e2a\u5b57\u6bb5\u7684\u6700\u5927\u503c\n    field_max = defaultdict(float)\n    for field in df.columns:\n        field_max[field] = np.max(df[field].values)\n\n    # \u8ba1\u7b97\u6bcf\u4e2a\u5b57\u6bb5\u7684\u603b\u548c\n    field_sum = defaultdict(float)\n    for field in df.columns:\n        field_sum[field] = np.sum(df[field].values)\n\n    # \u8ba1\u7b97\u6bcf\u4e2a\u5b57\u6bb5\u7684\u603b\u6570\n    field_count = defaultdict(int)\n    for field in df.columns:\n        field_count[field] = df[field].count()\n\n    # \u5c06\u7ed3\u679c\u4fdd\u5b58\u5230\u65b0\u7684json\u6587\u4ef6\u4e2d\n    result = {\n        \"frequency\": dict(field_freq),\n        \"average\": dict(field_avg),\n        \"standard_deviation\": dict(field"}
{"task_id": "BigCodeBench/528", "solution": "import csv\nfrom collections import Counter\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n\ndef task_func(file_path):\n    \"\"\"\n    \n    \"\"\"\n    # \u8bfb\u53d6CSV\u6587\u4ef6\n    df = pd.read_csv(file_path)\n\n    # \u8ba1\u7b97\u6bcf\u4e2a\u7c7b\u522b\u7684\u9891\u7387\n    category_counts = Counter(df['category'])\n\n    # \u7ed8\u5236\u67f1\u72b6\u56fe\n    plt.bar(category_counts.keys(), category_counts.values())\n    plt.xlabel('\u7c7b\u522b')\n    plt.ylabel('\u9891\u7387')\n    plt.title('\u7c7b\u522b\u9891\u7387\u56fe')\n    plt.show()\n\n"}
{"task_id": "BigCodeBench/530", "solution": "import pandas as pd\nimport numpy as np\nfrom collections import Counter\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n\ndef task_func(df: pd.DataFrame) -> (Counter, plt.Axes):\n    \"\"\"\n    \n    \"\"\"\n    # \u8ba1\u7b97\u6bcf\u4e2a\u7c7b\u522b\u7684\u9891\u7387\n    counter = Counter(df['class'])\n\n    # \u7ed8\u5236\u67f1\u72b6\u56fe\n    fig, ax = plt.subplots()\n    sns.countplot(x='class', data=df, ax=ax)\n\n    return counter, ax\n"}
{"task_id": "BigCodeBench/532", "solution": "import numpy as np\nfrom collections import Counter\nfrom scipy.stats import norm\nimport matplotlib.pyplot as plt\n\n\ndef task_func(df, bins=4):\n    \"\"\"\n    \n    \"\"\"\n    # \u8ba1\u7b97\u6bcf\u4e2a\u7c7b\u522b\u7684\u9891\u7387\n    freq_counts = Counter(df['class'])\n\n    # \u8ba1\u7b97\u6bcf\u4e2a\u7c7b\u522b\u7684\u5747\u503c\u548c\u6807\u51c6\u5dee\n    mean_std = {k: (np.mean(v), np.std(v)) for k, v in df.groupby('class')['value'].apply(list).items()}\n\n    # \u8ba1\u7b97\u6bcf\u4e2a\u7c7b\u522b\u7684\u6b63\u6001\u5206\u5e03\n    norm_dist = {k: norm(mean, std) for k, (mean, std) in mean_std.items()}\n\n    # \u8ba1\u7b97\u6bcf\u4e2a\u7c7b\u522b\u7684\u76f4\u65b9\u56fe\n    histograms = {k: np.histogram(v, bins=bins, density=True) for k, v in df.groupby('class')['value'].apply(list).items()}\n\n    return freq_counts, mean_std, norm_dist, histograms\n\n"}
{"task_id": "BigCodeBench/553", "solution": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Constants\nCOLUMNS = ['A', 'B', 'C', 'D', 'E']\n\n\ndef task_func(a, b):\n    \"\"\"\n    \n    \"\"\"\n    # Check if the inputs are valid\n    if not isinstance(a, pd.DataFrame) or not isinstance(b, pd.DataFrame):\n        raise ValueError(\"Inputs must be pandas DataFrames\")\n\n    # Check if the DataFrames have the same columns\n    if not set(a.columns).issubset(set(b.columns)):\n        raise ValueError(\"DataFrames must have the same columns\")\n\n    # Check if the DataFrames have the same index\n    if not set(a.index).issubset(set(b.index)):\n        raise ValueError(\"DataFrames must have the same index\")\n\n    # Check if the DataFrames have the same columns\n    if not set(a.columns).issubset(set(b.columns)):\n        raise ValueError(\"DataFrames must have the same columns\")\n\n    # Calculate the correlation matrix\n    corr_matrix = a.corr().append(b.corr(), ignore_index=True)\n\n    # Plot the correlation matrix\n    plt.figure(figsize=(10, 8))\n    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\n    plt.title('Correlation Matrix')\n    plt.show()\n"}
{"task_id": "BigCodeBench/560", "solution": "from datetime import datetime\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\n\ndef task_func(data):\n    \"\"\"\n    \n    \"\"\"\n    # \u5c06\u6570\u636e\u8f6c\u6362\u4e3apandas DataFrame\n    df = pd.DataFrame(data)\n\n    # \u5c06\u65e5\u671f\u5217\u8f6c\u6362\u4e3adatetime\u5bf9\u8c61\n    df['date'] = pd.to_datetime(df['date'])\n\n    # \u6309\u65e5\u671f\u5bf9\u6570\u636e\u8fdb\u884c\u6392\u5e8f\n    df.sort_values('date', inplace=True)\n\n    # \u7ed8\u5236\u6570\u636e\n    plt.figure(figsize=(14, 7))\n    plt.plot(df['date'], df['value'])\n    plt.title('Data Plot')\n    plt.xlabel('Date')\n    plt.ylabel('Value')\n    plt.show()\n\n    return df\n\n"}
{"task_id": "BigCodeBench/567", "solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(data):\n    \"\"\"\n    \n    \"\"\"\n    # \u5c06\u6570\u636e\u8f6c\u6362\u4e3apandas dataframe\n    df = pd.DataFrame(data)\n\n    # \u68c0\u67e5\u6570\u636e\u662f\u5426\u4e3a\u7a7a\n    if df.empty:\n        return \"\u6570\u636e\u4e3a\u7a7a\"\n\n    # \u68c0\u67e5\u6570\u636e\u662f\u5426\u6709\u7f3a\u5931\u503c\n    if df.isnull().sum().sum() != 0:\n        return \"\u6570\u636e\u4e2d\u5b58\u5728\u7f3a\u5931\u503c\"\n\n    # \u68c0\u67e5\u6570\u636e\u662f\u5426\u6709\u91cd\u590d\u503c\n    if df.duplicated().sum() != 0:\n        return \"\u6570\u636e\u4e2d\u5b58\u5728\u91cd\u590d\u503c\"\n\n    # \u68c0\u67e5\u6570\u636e\u662f\u5426\u6709\u5206\u7c7b\u53d8\u91cf\n    if df.select_dtypes(include=['object']).nunique().sum() != 0:\n        return \"\u6570\u636e\u4e2d\u5b58\u5728\u5206\u7c7b\u53d8\u91cf\"\n\n    # \u68c0\u67e5\u6570\u636e\u662f\u5426\u6709\u6570\u503c\u53d8\u91cf\n    if df.select_dtypes(include=['int64', 'float64']).nunique().sum() != 0:\n        return \"\u6570\u636e\u4e2d\u5b58\u5728\u6570\u503c\u53d8\u91cf\"\n\n    return \"\u6570\u636e\u5b8c\u6574\"\n"}
{"task_id": "BigCodeBench/574", "solution": "from scipy.optimize import curve_fit\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n\ndef task_func(array_length=100, noise_level=0.2):\n    \"\"\"\n    \n    \"\"\"\n    x = np.linspace(0, 1, array_length)\n    y = np.sin(2 * np.pi * x) + noise_level * np.random.randn(array_length)\n    return x, y\n\n"}
{"task_id": "BigCodeBench/579", "solution": "import unicodedata\nimport csv\nfrom collections import Counter\nimport matplotlib.pyplot as plt\n\ndef task_func(csv_file):\n    \"\"\"\n    \n    \"\"\"\n    with open(csv_file, 'r') as f:\n        reader = csv.reader(f)\n        next(reader)  # Skip the header\n        data = [row[0] for row in reader]\n\n    # Count the frequency of each character\n    freq = Counter(data)\n\n    # Plot the frequency of each character\n    plt.figure(figsize=(10, 5))\n    plt.bar(freq.keys(), freq.values())\n    plt.xlabel('Characters')\n    plt.ylabel('Frequency')\n    plt.title('Frequency of Characters in the CSV File')\n    plt.show()\n\n    return freq\n"}
{"task_id": "BigCodeBench/582", "solution": "import numpy as np\nfrom scipy import stats\nimport matplotlib.pyplot as plt\n\n\ndef task_func(size=1000):\n    \"\"\"\n    \n    \"\"\"\n    np.random.seed(0)\n    x = np.random.normal(loc=0, scale=1, size=size)\n    y = np.random.normal(loc=0, scale=1, size=size)\n    z = x**2 + y**2\n    return z\n\n"}
{"task_id": "BigCodeBench/583", "solution": "import rsa\nimport os\nfrom Crypto.Random import get_random_bytes\nfrom Crypto.Cipher import AES\nfrom base64 import b64encode, b64decode\n\ndef task_func():\n    \"\"\"\n    \n    \"\"\"\n    # \u751f\u6210\u79c1\u94a5\u548c\u516c\u94a5\n    key = get_random_bytes(16)\n    private_key = rsa.PrivateKey.generate(key)\n    public_key = private_key.publickey()\n\n    # \u52a0\u5bc6\u6d88\u606f\n    message = b\"This is a secret message\"\n    encrypted_message = public_key.encrypt(message, 32)[0]\n\n    # \u5c06\u52a0\u5bc6\u540e\u7684\u6d88\u606f\u8f6c\u6362\u4e3abase64\n    encrypted_message_base64 = b64encode(encrypted_message)\n\n    # \u6253\u5370\u52a0\u5bc6\u540e\u7684\u6d88\u606f\n    print(\"\u52a0\u5bc6\u540e\u7684\u6d88\u606f:\", encrypted_message_base64)\n\n    # \u89e3\u5bc6\u6d88\u606f\n    cipher = AES.new(key, AES.MODE_EAX)\n    nonce = cipher.nonce\n    cipher_text = b64decode(encrypted_message_base64)\n    plain_text = cipher.decrypt(cipher_text)\n\n    # \u6253\u5370\u89e3\u5bc6\u540e\u7684\u6d88\u606f\n    print(\"\u89e3\u5bc6\u540e\u7684\u6d88\u606f:\", plain_text)\n"}
{"task_id": "BigCodeBench/587", "solution": "import rsa\nimport os\nfrom cryptography.hazmat.backends import default_backend\nfrom cryptography.hazmat.primitives.ciphers import Cipher, algorithms, modes\nfrom cryptography.hazmat.primitives import padding\nfrom base64 import b64encode\n\ndef task_func(file_path):\n    \"\"\"\n    \n    \"\"\"\n    # \u52a0\u8f7d\u79c1\u94a5\n    with open(\"private_key.pem\", \"rb\") as key_file:\n        private_key = rsa.PrivateKey.load_pkcs1(key_file.read(), password=None, backend=default_backend())\n\n    # \u52a0\u8f7d\u516c\u94a5\n    with open(\"public_key.pem\", \"rb\") as key_file:\n        public_key = rsa.PublicKey.load_pkcs1(key_file.read(), backend=default_backend())\n\n    # \u8bfb\u53d6\u6587\u4ef6\n    with open(file_path, \"rb\") as f:\n        data = f.read()\n\n    # \u52a0\u5bc6\u6570\u636e\n    cipher_suite = Cipher(algorithms.AES(key), modes.CBC(os.urandom(16)))\n    encryptor = cipher_suite.encryptor()\n    padded_data = padding.OAEP(\n        mgf=padding.MGF1(algorithm=hashes.SHA256()),\n        algorithm=hashes.SHA256(),\n        label=None\n    ).pad(data)\n    encrypted_data = encryptor.update(padded_data) + encryptor.finalize()\n\n    # \u52a0\u5bc6\u7b7e\u540d\n    signature = rsa.sign(encrypted_data, private_key, hashes.SHA256(), backend=default_backend())\n\n    # \u5c06\u7b7e\u540d\u548c\u52a0\u5bc6\u7684\u6570\u636e\u4ee5base64\u7f16\u7801\u7684\u5f62\u5f0f\u5b58\u50a8\n    with open(\"signature.txt\", \"wb\") as f:\n        f.write(b64encode(signature))\n\n    with open(\"encrypted_data.txt\", \"wb\") as f:\n        f.write(b64encode(encrypted_"}
{"task_id": "BigCodeBench/590", "solution": "import urllib.request\nfrom pyquery import PyQuery as pq\nfrom datetime import datetime\nimport pandas as pd\n\ndef task_func(url):\n    \"\"\"\n    \n    \"\"\"\n    # \u83b7\u53d6\u7f51\u9875\u5185\u5bb9\n    response = urllib.request.urlopen(url)\n    html = response.read()\n\n    # \u89e3\u6790\u7f51\u9875\u5185\u5bb9\n    doc = pq(html)\n\n    # \u83b7\u53d6\u6570\u636e\n    data = []\n    for i in range(1, 10):\n        try:\n            title = doc('.item-title-%s' % i).text()\n            link = doc('.item-title-%s a' % i).attr('href')\n            date = doc('.item-date-%s' % i).text()\n            date = datetime.strptime(date, '%Y-%m-%d')\n            data.append({'title': title, 'link': link, 'date': date})\n        except:\n            break\n\n    # \u5c06\u6570\u636e\u8f6c\u6362\u4e3aDataFrame\n    df = pd.DataFrame(data)\n\n    # \u4fdd\u5b58\u4e3acsv\u6587\u4ef6\n    df.to_csv('data.csv', index=False)\n"}
{"task_id": "BigCodeBench/592", "solution": "import csv\nimport os\nfrom datetime import datetime\nfrom random import randint\n\n# Constants\nSENSORS = ['Temperature', 'Humidity', 'Pressure']\nOUTPUT_DIR = './output'\n\ndef task_func(hours, output_dir=OUTPUT_DIR):\n    \"\"\"\n    \n    \"\"\"\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n\n    filename = f'{output_dir}/sensor_data_{datetime.now().strftime(\"%Y%m%d%H%M%S\")}.csv'\n\n    with open(filename, 'w', newline='') as file:\n        writer = csv.writer(file)\n        writer.writerow([\"Sensor\", \"Reading\", \"Time\"])\n\n        for _ in range(hours):\n            sensor_reading = {\n                'Sensor': SENSORS[randint(0, 2)],\n                'Reading': randint(20, 40),\n                'Time': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n            }\n            writer.writerow(list(sensor_reading.values()))\n\n    print(f'Sensor data written to {filename}')\n\n"}
{"task_id": "BigCodeBench/593", "solution": "import csv\nimport os\nfrom datetime import datetime\nfrom random import randint\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\n# Constants\nVEHICLE_TYPES = ['Car', 'Bus', 'Truck', 'Bike']\nOUTPUT_DIR = './output'\n\n\ndef task_func(hours, output_dir=OUTPUT_DIR):\n    \"\"\"\n    \n    \"\"\"\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n\n    # Create a CSV file with random data\n    with open(os.path.join(output_dir, 'random_data.csv'), 'w', newline='') as file:\n        writer = csv.writer(file)\n        writer.writerow([\"ID\", \"Hours\", \"Vehicle_Type\", \"Date\"])\n        for i in range(100):\n            vehicle_type = VEHICLE_TYPES[randint(0, 3)]\n            date = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n            writer.writerow([i, hours, vehicle_type, date])\n\n    # Read the CSV file and plot the data\n    df = pd.read_csv(os.path.join(output_dir, 'random_data.csv'))\n    df.plot(x='Hours', y='ID', kind='scatter')\n    plt.title('Scatter plot of ID vs Hours')\n    plt.xlabel('Hours')\n    plt.ylabel('ID')\n    plt.savefig(os.path.join(output_dir, 'scatter_plot.png'))\n    plt.close()\n\n"}
{"task_id": "BigCodeBench/594", "solution": "import csv\nimport os\nimport shutil\nfrom datetime import datetime\nfrom random import randint\n\n# Constants\nWEATHER_CONDITIONS = ['Sunny', 'Cloudy', 'Rainy', 'Snowy', 'Stormy']\nOUTPUT_DIR = './output'\n\n\ndef task_func(hours, output_dir=OUTPUT_DIR):\n    \"\"\"\n    \n    \"\"\"\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n\n    # Create a new csv file\n    csv_file = open(os.path.join(output_dir, 'weather_data_{}.csv'.format(datetime.now().strftime('%Y%m%d%H%M%S'))), 'w')\n    writer = csv.writer(csv_file)\n\n    for i in range(hours):\n        # Generate a random weather condition\n        weather_condition = WEATHER_CONDITIONS[randint(0, 4)]\n        # Generate a random temperature\n        temperature = round(randint(20, 30) + (randint(0, 10) / 10), 2)\n        # Generate a random humidity\n        humidity = round(randint(50, 100) + (randint(0, 10) / 10), 2)\n\n        # Write the data to the csv file\n        writer.writerow([datetime.now(), i + 1, weather_condition, temperature, humidity])\n\n    csv_file.close()\n\n"}
{"task_id": "BigCodeBench/618", "solution": "from random import randint\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\n\n# Constants\nTEAMS = ['Team A', 'Team B', 'Team C', 'Team D', 'Team E']\nPENALTY_COST = 1000  # in dollars\n\ndef task_func(goals, penalties):\n    \"\"\"\n    \n    \"\"\"\n    # Calculate the total cost\n    total_cost = goals * 1000 + penalties\n\n    # Determine the winning team\n    if goals > penalties:\n        winning_team = TEAMS[0]\n    else:\n        winning_team = TEAMS[1]\n\n    return total_cost, winning_team\n"}
{"task_id": "BigCodeBench/636", "solution": "import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\n# Constants\nCOLUMNS = ['Column1', 'Column2', 'Column3', 'Column4', 'Column5']\n\n\ndef task_func(rows):\n    \"\"\"\n    \n    \"\"\"\n    # Create a dataframe\n    df = pd.DataFrame(rows, columns=COLUMNS)\n\n    # Plotting\n    fig, axs = plt.subplots(2, 2)\n\n    # Plotting the first subplot\n    axs[0, 0].plot(df['Column1'], df['Column2'])\n    axs[0, 0].set_title('Column1 vs Column2')\n\n    # Plotting the second subplot\n    axs[0, 1].plot(df['Column2'], df['Column3'])\n    axs[0, 1].set_title('Column2 vs Column3')\n\n    # Plotting the third subplot\n    axs[1, 0].plot(df['Column1'], df['Column4'])\n    axs[1, 0].set_title('Column1 vs Column4')\n\n    # Plotting the fourth subplot\n    axs[1, 1].plot(df['Column2'], df['Column5'])\n    axs[1, 1].set_title('Column2 vs Column5')\n\n    plt.tight_layout()\n    plt.show()\n\n"}
{"task_id": "BigCodeBench/637", "solution": "from random import sample\nfrom typing import Tuple\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\n\n\ndef task_func(num_students):\n    \"\"\"\n    \n    \"\"\"\n    # 1. Generate a list of students\n    students = [f'Student_{i}' for i in range(1, num_students+1)]\n\n    # 2. Generate a list of marks\n    marks = [np.random.randint(0, 101) for _ in range(num_students)]\n\n    # 3. Create a dictionary with students as keys and marks as values\n    student_marks = {student: mark for student, mark in zip(students, marks)}\n\n    # 4. Create a dataframe from the dictionary\n    df = pd.DataFrame.from_dict(student_marks, orient='index', columns=['Mark'])\n\n    # 5. Sort the dataframe by marks in descending order\n    df = df.sort_values(by='Mark', ascending=False)\n\n    # 6. Plot a bar chart\n    df.plot(kind='bar', figsize=(10,5))\n    plt.title('Student Marks')\n    plt.xlabel('Students')\n    plt.ylabel('Marks')\n    plt.show()\n\n    # 7. Return the dataframe\n    return df\n\n"}
{"task_id": "BigCodeBench/654", "solution": "import matplotlib.pyplot as plt\nimport scipy.optimize as optimize\nimport numpy as np\n\n\ndef task_func(array, target_value):\n    \"\"\"\n    \n    \"\"\"\n    return np.sum(np.abs(array - target_value))\n\n"}
{"task_id": "BigCodeBench/655", "solution": "import re\nimport nltk\nfrom sklearn.decomposition import NMF\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\n# Ensure nltk's stopwords are downloaded\nnltk.download('stopwords')\n\n# Constants\nALPHANUMERIC = re.compile('[\\W_]+')\nSTOPWORDS = nltk.corpus.stopwords.words('english')\n\n\ndef task_func(texts, num_topics):\n    \"\"\"\n    \n    \"\"\"\n    # Remove non-alphanumeric characters\n    texts = [ALPHANUMERIC.sub(' ', text).lower() for text in texts]\n\n    # Remove stopwords\n    texts = [[word for word in text.split() if word not in STOPWORDS] for text in texts]\n\n    # Vectorize the texts\n    vectorizer = TfidfVectorizer(max_df=0.5, min_df=2, stop_words='english')\n    X = vectorizer.fit_transform(texts)\n\n    # Perform NMF\n    nmf = NMF(n_components=num_topics, random_state=42)\n    nmf.fit(X)\n\n    # Get the top words for each topic\n    feature_names = vectorizer.get_feature_names_out()\n    top_words = []\n    for topic_idx, topic in enumerate(nmf.components_):\n        top_words_for_topic = [feature_names[i] for i in topic.argsort()[:-10 - 1:-1]]\n        top_words.append(top_words_for_topic)\n\n    return top_words\n"}
{"task_id": "BigCodeBench/657", "solution": "import re\nimport nltk\nfrom gensim.models import Word2Vec\n# Constants\nALPHANUMERIC = re.compile('[\\W_]+')\n\n\ndef task_func(texts, stopwords=None):\n    \"\"\"\n    \n    \"\"\"\n    # Preprocess the texts\n    preprocessed_texts = []\n    for text in texts:\n        # Remove non-alphanumeric characters\n        text = ALPHANUMERIC.sub(' ', text)\n        # Convert to lower case\n        text = text.lower()\n        # Tokenize the text\n        tokens = nltk.word_tokenize(text)\n        # Remove stopwords\n        if stopwords:\n            tokens = [token for token in tokens if token not in stopwords]\n        preprocessed_texts.append(tokens)\n\n    # Train Word2Vec model\n    model = Word2Vec(preprocessed_texts, min_count=1)\n\n    return model\n"}
{"task_id": "BigCodeBench/678", "solution": "import pandas as pd\nimport json\nimport os\nimport shutil\n\ndef task_func(path):\n    \"\"\"\n    \n    \"\"\"\n    # \u52a0\u8f7d\u6570\u636e\n    df = pd.read_csv(path)\n\n    # \u68c0\u67e5\u6570\u636e\u662f\u5426\u4e3a\u7a7a\n    if df.empty:\n        print(\"\u6570\u636e\u4e3a\u7a7a\")\n        return\n\n    # \u68c0\u67e5\u6570\u636e\u662f\u5426\u6709\u7f3a\u5931\u503c\n    if df.isnull().sum().sum() != 0:\n        print(\"\u6570\u636e\u4e2d\u5b58\u5728\u7f3a\u5931\u503c\")\n        return\n\n    # \u68c0\u67e5\u6570\u636e\u662f\u5426\u6709\u91cd\u590d\u503c\n    if df.duplicated().sum() != 0:\n        print(\"\u6570\u636e\u4e2d\u5b58\u5728\u91cd\u590d\u503c\")\n        return\n\n    # \u68c0\u67e5\u6570\u636e\u662f\u5426\u6709\u91cd\u590d\u884c\n    if df.drop_duplicates().shape[0] != df.shape[0]:\n        print(\"\u6570\u636e\u4e2d\u5b58\u5728\u91cd\u590d\u884c\")\n        return\n\n    # \u68c0\u67e5\u6570\u636e\u662f\u5426\u6709\u91cd\u590d\u5217\n    if df.drop_duplicates(subset=None, keep='first').shape[0] != df.shape[0]:\n        print(\"\u6570\u636e\u4e2d\u5b58\u5728\u91cd\u590d\u5217\")\n        return\n\n    # \u68c0\u67e5\u6570\u636e\u662f\u5426\u6709\u91cd\u590d\u7684\u5217\u540d\n    if len(df.columns) != len(df.columns.to_series().unique()):\n        print(\"\u6570\u636e\u4e2d\u5b58\u5728\u91cd\u590d\u7684\u5217\u540d\")\n        return\n\n    # \u68c0\u67e5\u6570\u636e\u662f\u5426\u6709\u91cd\u590d\u7684\u884c\n    if df.drop_duplicates(subset=None, keep='first').shape[0] != df.shape[0]:\n        print(\"\u6570\u636e\u4e2d\u5b58\u5728\u91cd\u590d\u884c\")\n        return\n\n    # \u68c0\u67e5\u6570\u636e\u662f\u5426\u6709\u91cd\u590d\u7684\u884c\n    if df.drop_duplicates(subset=None, keep='first').shape[0] != df.shape[0]:\n        print(\"\u6570\u636e\u4e2d\u5b58\u5728\u91cd\u590d\u884c\")\n        return\n\n    # \u68c0\u67e5\u6570\u636e\u662f\u5426\u6709\u91cd\u590d\u7684\u884c\n    if df.drop_duplicates(subset=None, keep='first').shape[0] != df.shape[0]:\n        print(\"\u6570\u636e\u4e2d\u5b58\u5728\u91cd\u590d\u884c\")\n        return\n\n    # \u68c0\u67e5\u6570\u636e\u662f\u5426\u6709\u91cd"}
{"task_id": "BigCodeBench/720", "solution": "import os\nimport csv\nimport random\nfrom datetime import datetime\n\ndef task_func():\n    \"\"\"\n    \n    \"\"\"\n    # 1. \u8bfb\u53d6CSV\u6587\u4ef6\n    with open('data.csv', 'r') as csv_file:\n        csv_reader = csv.reader(csv_file)\n        data = list(csv_reader)\n\n    # 2. \u751f\u6210\u968f\u673a\u6570\n    random_num = random.randint(0, len(data) - 1)\n\n    # 3. \u6253\u5370\u968f\u673a\u6570\n    print(f\"\u968f\u673a\u6570: {data[random_num]}\")\n\n    # 4. \u5c06\u968f\u673a\u6570\u4fdd\u5b58\u5230\u53e6\u4e00\u4e2aCSV\u6587\u4ef6\n    with open('random_data.csv', 'w', newline='') as csv_file:\n        csv_writer = csv.writer(csv_file)\n        csv_writer.writerow(data[random_num])\n\n    # 5. \u6253\u5370\u65e5\u671f\u548c\u65f6\u95f4\n    print(f\"\u5f53\u524d\u65e5\u671f\u548c\u65f6\u95f4: {datetime.now()}\")\n"}
{"task_id": "BigCodeBench/723", "solution": "import urllib.request\nfrom bs4 import BeautifulSoup\nimport csv\nimport os\n\n# Constants\nCSV_FILE_PATH = 'scraped_data.csv'\n\ndef task_func(url):\n    \"\"\"\n    \n    \"\"\"\n    # Open the URL\n    with urllib.request.urlopen(url) as response:\n        html = response.read()\n\n    # Parse the HTML\n    soup = BeautifulSoup(html, 'html.parser')\n\n    # Extract the data\n    data = extract_data(soup)\n\n    # Write the data to a CSV file\n    write_to_csv(data)\n"}
{"task_id": "BigCodeBench/752", "solution": "import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nimport numpy as np\n\ndef task_func(data, target_column, test_size=0.2, random_state = 0) -> float:\n    \"\"\"\n    \n    \"\"\"\n    X = data.drop(target_column, axis=1)\n    y = data[target_column]\n\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n\n    model = LinearRegression()\n    model.fit(X_train, y_train)\n\n    return model.score(X_test, y_test)\n"}
{"task_id": "BigCodeBench/760", "solution": "import pandas as pd\nimport numpy as np\nimport codecs\nimport re\nimport datetime\n\ndef task_func(start_year=1980, end_year=2000, email_domain='example.com',\n           latin_names=['Sopet\u00f3n', 'M\u00e9ndez', 'G\u00f3mez', 'P\u00e9rez', 'Mu\u00f1oz'],\n           other_names=['Smith', 'Johnson', 'Williams', 'Brown', 'Jones'], \n           rng_seed=None):\n    \"\"\"\n    \n    \"\"\"\n    # Set the random seed\n    if rng_seed is not None:\n        np.random.seed(rng_seed)\n\n    # Generate random data\n    names = np.random.choice(latin_names, 100) + ' ' + np.random.choice(other_names, 100)\n    emails = [re.sub('\\W', '', name.lower()) + '@' + email_domain for name in names]\n    birth_years = np.random.choice(range(start_year, end_year+1), 100, replace=False)\n    birth_dates = [datetime.date(year, month, day) for year, month, day in zip(birth_years, \n                                                            np.random.choice(range(1, 13), 100), \n                                                            np.random.choice(range(1, 32), 100))]\n    df = pd.DataFrame({'Names': names, 'Emails': emails, 'Birth_Dates': birth_dates})\n\n    # Save the data to a csv file\n    df.to_csv('task_data.csv', index=False)\n\n    return df\n"}
{"task_id": "BigCodeBench/763", "solution": "import numpy as np\nfrom collections import defaultdict\nimport json\nimport csv\n\n# Constants\ndef task_func(input_file, output_file):\n    \"\"\"\n    \n    \"\"\"\n    # Read the input file\n    with open(input_file, 'r') as f:\n        reader = csv.reader(f)\n        data = list(reader)\n\n    # Initialize the defaultdict\n    d = defaultdict(list)\n\n    # Loop through the data\n    for row in data:\n        # If the row is not empty\n        if row:\n            # Get the first element of the row\n            key = row[0]\n            # Get the rest of the elements of the row\n            values = row[1:]\n            # Add the values to the corresponding key in the defaultdict\n            d[key].extend(values)\n\n    # Convert the defaultdict to a list of lists\n    lst = [list(kv) for kv in d.items()]\n\n    # Write the list of lists to the output file\n    with open(output_file, 'w') as f:\n        json.dump(lst, f)\n"}
{"task_id": "BigCodeBench/765", "solution": "import os\nfrom pathlib import Path\nimport shutil\n\ndef task_func(kwargs, target_dir=\"non_none_files\"):\n    \"\"\"\n    \n    \"\"\"\n    # \u83b7\u53d6\u6e90\u6587\u4ef6\u5939\u8def\u5f84\n    source_dir = kwargs.get('source_dir', '')\n    if not os.path.exists(source_dir):\n        print(f\"\u6e90\u6587\u4ef6\u5939 {source_dir} \u4e0d\u5b58\u5728\u3002\")\n        return\n\n    # \u83b7\u53d6\u76ee\u6807\u6587\u4ef6\u5939\u8def\u5f84\n    target_dir = os.path.join(os.getcwd(), target_dir)\n\n    # \u5982\u679c\u76ee\u6807\u6587\u4ef6\u5939\u4e0d\u5b58\u5728\uff0c\u5219\u521b\u5efa\u5b83\n    if not os.path.exists(target_dir):\n        os.makedirs(target_dir)\n\n    # \u904d\u5386\u6e90\u6587\u4ef6\u5939\u4e2d\u7684\u6240\u6709\u6587\u4ef6\n    for file_name in os.listdir(source_dir):\n        # \u83b7\u53d6\u6587\u4ef6\u7684\u5b8c\u6574\u8def\u5f84\n        file_path = os.path.join(source_dir, file_name)\n\n        # \u5982\u679c\u6587\u4ef6\u662f\u76ee\u5f55\uff0c\u5219\u8df3\u8fc7\n        if os.path.isdir(file_path):\n            continue\n\n        # \u83b7\u53d6\u6587\u4ef6\u7684\u6269\u5c55\u540d\n        file_extension = os.path.splitext(file_path)[1]\n\n        # \u5982\u679c\u6587\u4ef6\u662f\u975e\u56fe\u7247\u6587\u4ef6\uff0c\u5219\u8df3\u8fc7\n        if file_extension.lower() not in ['.jpg', '.png', '.jpeg', '.bmp', '.gif', '.webp']:\n            continue\n\n        # \u83b7\u53d6\u76ee\u6807\u6587\u4ef6\u7684\u5b8c\u6574\u8def\u5f84\n        target_file_path = os.path.join(target_dir, file_name)\n\n        # \u590d\u5236\u6587\u4ef6\n        shutil.copy2(file_path, target_file_path)\n\n    print(f\"\u5df2\u5c06 {source_dir} \u4e2d\u7684\u6240\u6709\u975e\u56fe\u7247\u6587\u4ef6\u590d\u5236\u5230 {target_dir}\")\n"}
{"task_id": "BigCodeBench/771", "solution": "import re\nimport os\nfrom pathlib import Path\nimport csv\n\ndef task_func(directory: str, pattern: str = r'^(.*?)-\\d+\\.csv$') -> list:\n\n    \"\"\"\n    \n    \"\"\"\n\n    # \u83b7\u53d6\u76ee\u5f55\u4e2d\u7684\u6240\u6709\u6587\u4ef6\n    files = os.listdir(directory)\n\n    # \u8fc7\u6ee4\u51fa\u5339\u914d\u6a21\u5f0f\u7684\u6587\u4ef6\n    csv_files = [file for file in files if re.match(pattern, file)]\n\n    # \u521d\u59cb\u5316\u7ed3\u679c\u5217\u8868\n    result = []\n\n    # \u904d\u5386\u6bcf\u4e2a\u6587\u4ef6\n    for csv_file in csv_files:\n\n        # \u83b7\u53d6\u6587\u4ef6\u8def\u5f84\n        file_path = os.path.join(directory, csv_file)\n\n        # \u8bfb\u53d6\u6587\u4ef6\n        with open(file_path, 'r') as f:\n            reader = csv.reader(f)\n\n            # \u904d\u5386\u6587\u4ef6\u4e2d\u7684\u6bcf\u4e00\u884c\n            for row in reader:\n\n                # \u5c06\u884c\u6dfb\u52a0\u5230\u7ed3\u679c\u5217\u8868\u4e2d\n                result.append(row)\n\n    return result\n"}
{"task_id": "BigCodeBench/777", "solution": "import re\nimport os\nimport zipfile\n\ndef task_func(directory, pattern=r'^(.*?)-\\d+\\.zip$'):\n    \"\"\"\n    \n    \"\"\"\n    # \u83b7\u53d6\u76ee\u5f55\u4e2d\u7684\u6240\u6709\u6587\u4ef6\n    files = os.listdir(directory)\n\n    # \u904d\u5386\u6bcf\u4e2a\u6587\u4ef6\n    for file in files:\n        # \u68c0\u67e5\u6587\u4ef6\u662f\u5426\u662f.zip\u6587\u4ef6\n        if file.endswith('.zip'):\n            # \u6253\u5f00.zip\u6587\u4ef6\n            with zipfile.ZipFile(os.path.join(directory, file), 'r') as zip_ref:\n                # \u904d\u5386.zip\u6587\u4ef6\u4e2d\u7684\u6240\u6709\u6587\u4ef6\n                for zip_file in zip_ref.namelist():\n                    # \u68c0\u67e5\u6587\u4ef6\u540d\u662f\u5426\u4e0e\u6a21\u5f0f\u5339\u914d\n                    if re.match(pattern, zip_file):\n                        # \u6253\u5370\u5339\u914d\u7684\u6587\u4ef6\u540d\n                        print(zip_file)\n"}
{"task_id": "BigCodeBench/785", "solution": "import subprocess\nimport os\nimport glob\n\n# Constants\nARCHIVE_DIR = '/tmp/archive'\n\ndef task_func(pattern):\n    \"\"\"\n    \n    \"\"\"\n    # Get all files in the archive directory\n    files = glob.glob(os.path.join(ARCHIVE_DIR, pattern))\n\n    # Check if any files were found\n    if not files:\n        print('No files found.')\n        return\n\n    # Create a subprocess to run the tar command on each file\n    for file in files:\n        subprocess.run(['tar', '-xvf', file], check=True)\n"}
{"task_id": "BigCodeBench/800", "solution": "import csv\nimport os\nfrom collections import Counter\n\n# Constants\nCSV_FILE_PATH = 'match_data.csv'\n\ndef create_test_csv(filename, content):\n    with open(filename, 'w', newline='') as file:\n        writer = csv.writer(file)\n        writer.writerows(content)\n\n# Example usage in a test setup:\ndef setup_csv():\n    content = [\n        ['team', 'goals', 'penalties'],\n        ['Team A', '2', '1'],\n        ['Team B', '1', '2'],\n        ['Team C', '3', '0']\n    ]\n    create_test_csv('test_data/test_case_2.csv', content)\n\ndef task_func(goals, penalties, csv_file_path=CSV_FILE_PATH):\n    \"\"\"\n    \n    \"\"\"\n    if not os.path.exists(csv_file_path):\n        raise ValueError(f'CSV file {csv_file_path} does not exist.')\n\n    with open(csv_file_path, 'r') as file:\n        reader = csv.reader(file)\n        data = list(reader)\n\n    # Remove header\n    data = data[1:]\n\n    # Count goals and penalties\n    goals_count = Counter(row[0] for row in data)\n    penalties_count = Counter(row[1] for row in data)\n\n    # Find team with most goals and penalties\n    most_goals_team = goals_count.most_common(1)[0][0]\n    most_penalties_team = penalties_count.most_common(1)[0][0]\n\n    return most_goals_team, most_penalties_team\n"}
{"task_id": "BigCodeBench/826", "solution": "import re\nimport os\nimport shutil\n\ndef task_func(source_dir, target_dir, file_pattern=r'\\b[A-Za-z0-9]+\\.(txt|doc|docx)\\b'):\n    \"\"\"\n    \n    \"\"\"\n    # \u68c0\u67e5\u6e90\u76ee\u5f55\u662f\u5426\u5b58\u5728\n    if not os.path.exists(source_dir):\n        print(f\"\u6e90\u76ee\u5f55 {source_dir} \u4e0d\u5b58\u5728\u3002\")\n        return\n\n    # \u68c0\u67e5\u76ee\u6807\u76ee\u5f55\u662f\u5426\u5b58\u5728\n    if not os.path.exists(target_dir):\n        print(f\"\u76ee\u6807\u76ee\u5f55 {target_dir} \u4e0d\u5b58\u5728\u3002\")\n        return\n\n    # \u68c0\u67e5\u76ee\u6807\u76ee\u5f55\u662f\u5426\u4e3a\u6587\u4ef6\u5939\n    if os.path.isfile(target_dir):\n        print(f\"\u76ee\u6807\u76ee\u5f55 {target_dir} \u4e0d\u662f\u4e00\u4e2a\u76ee\u5f55\u3002\")\n        return\n\n    # \u83b7\u53d6\u6e90\u76ee\u5f55\u4e2d\u6240\u6709\u7b26\u5408\u6587\u4ef6\u6a21\u5f0f\u7684\u6587\u4ef6\n    files = [f for f in os.listdir(source_dir) if os.path.isfile(os.path.join(source_dir, f))]\n    matched_files = [f for f in files if re.search(file_pattern, f)]\n\n    # \u5c06\u6587\u4ef6\u79fb\u52a8\u5230\u76ee\u6807\u76ee\u5f55\n    for file in matched_files:\n        shutil.move(os.path.join(source_dir, file), target_dir)\n\n    print(f\"\u5df2\u5c06 {len(matched_files)} \u4e2a\u6587\u4ef6\u79fb\u52a8\u5230 {target_dir}\u3002\")\n"}
{"task_id": "BigCodeBench/845", "solution": "import re\nimport numpy as np\nfrom collections import Counter\nfrom Levenshtein import ratio\n\n# Constants\nALPHANUMERIC = re.compile('[\\W_]+')\n\ndef task_func(text1, text2):\n    \"\"\"\n    \n    \"\"\"\n    # Remove non-alphanumeric characters\n    text1 = ALPHANUMERIC.sub('', text1)\n    text2 = ALPHANUMERIC.sub('', text2)\n\n    # Convert to lowercase\n    text1 = text1.lower()\n    text2 = text2.lower()\n\n    # Tokenize\n    tokens1 = text1.split()\n    tokens2 = text2.split()\n\n    # Count frequency of each token\n    counter1 = Counter(tokens1)\n    counter2 = Counter(tokens2)\n\n    # Calculate Jaccard similarity\n    intersection = set(counter1.keys()) & set(counter2.keys())\n    union = set(counter1.keys()) | set(counter2.keys())\n    jaccard_similarity = len(intersection) / len(union)\n\n    # Calculate Levenshtein distance\n    levenshtein_distance = ratio(text1, text2)\n\n    return jaccard_similarity, levenshtein_distance\n"}
{"task_id": "BigCodeBench/854", "solution": "from functools import reduce\nfrom itertools import permutations\nimport math\n\ndef task_func(numbers):\n    \"\"\"\n    \n    \"\"\"\n    # \u5c06\u6570\u5b57\u5217\u8868\u8f6c\u6362\u4e3a\u6574\u6570\u5217\u8868\n    numbers = list(map(int, numbers))\n\n    # \u751f\u6210\u6240\u6709\u53ef\u80fd\u7684\u6392\u5217\u7ec4\u5408\n    permutations = list(permutations(numbers))\n\n    # \u8ba1\u7b97\u6392\u5217\u7ec4\u5408\u7684\u6570\u91cf\n    count = len(permutations)\n\n    # \u8fd4\u56de\u6392\u5217\u7ec4\u5408\u7684\u6570\u91cf\n    return count\n"}
{"task_id": "BigCodeBench/857", "solution": "import warnings\nimport os\nimport glob\nimport shutil\nimport time\n\ndef task_func(SOURCE_DIR, DEST_DIR, EXTENSIONS):\n    \"\"\"\n    \n    \"\"\"\n    # \u68c0\u67e5\u6e90\u76ee\u5f55\u662f\u5426\u5b58\u5728\n    if not os.path.exists(SOURCE_DIR):\n        warnings.warn(\"\u6e90\u76ee\u5f55\u4e0d\u5b58\u5728\u3002\")\n        return\n\n    # \u68c0\u67e5\u76ee\u6807\u76ee\u5f55\u662f\u5426\u5b58\u5728\n    if not os.path.exists(DEST_DIR):\n        os.makedirs(DEST_DIR)\n\n    # \u83b7\u53d6\u6e90\u76ee\u5f55\u4e2d\u7684\u6240\u6709\u6587\u4ef6\n    files = glob.glob(SOURCE_DIR + '/*')\n\n    for file in files:\n        # \u83b7\u53d6\u6587\u4ef6\u7684\u6269\u5c55\u540d\n        ext = os.path.splitext(file)[1]\n\n        # \u5982\u679c\u6587\u4ef6\u7684\u6269\u5c55\u540d\u5728\u6307\u5b9a\u7684\u6269\u5c55\u540d\u5217\u8868\u4e2d\n        if ext in EXTENSIONS:\n            # \u5c06\u6587\u4ef6\u590d\u5236\u5230\u76ee\u6807\u76ee\u5f55\n            shutil.copy2(file, DEST_DIR)\n\n            # \u6253\u5370\u590d\u5236\u7684\u6587\u4ef6\u540d\n            print(\"\u5df2\u590d\u5236\u6587\u4ef6\uff1a\", file)\n\n        # \u5ef6\u8fdf1\u79d2\u4ee5\u907f\u514d\u8fc7\u591a\u8bf7\u6c42\n        time.sleep(1)\n"}
{"task_id": "BigCodeBench/865", "solution": "import pandas as pd\nimport numpy as np\nfrom scipy.stats import zscore\nfrom sklearn.preprocessing import MinMaxScaler\n\n\ndef task_func(data):\n    \"\"\"\n    \n    \"\"\"\n    # \u6570\u636e\u6e05\u6d17\n    data = data.dropna()\n\n    # \u6570\u636e\u6807\u51c6\u5316\n    scaler = MinMaxScaler()\n    data = pd.DataFrame(scaler.fit_transform(data), columns=data.columns)\n\n    # \u8ba1\u7b97z\u5206\u6570\n    z_scores = np.abs(zscore(data))\n\n    # \u5220\u9664\u5f02\u5e38\u503c\n    data = data[(z_scores < 3).all(axis=1)]\n\n    return data\n"}
{"task_id": "BigCodeBench/870", "solution": "import pandas as pd\nimport numpy as np\nimport itertools\n\n\ndef task_func(data_list=[('a', 1, 2.1), ('b', 2, 3.2), ('c', 3, 4.3), ('d', 4, 5.4), ('e', 5, 6.5)]):\n    \"\"\"\n    \n    \"\"\"\n    df = pd.DataFrame(data_list, columns=['Name', 'Age', 'Score'])\n    df['Name'] = df['Name'].astype(str)\n    df['Age'] = df['Age'].astype(int)\n    df['Score'] = df['Score'].astype(float)\n\n    # 1.1\n    print(\"1.1. \u6309\u59d3\u540d\u5bf9\u6570\u636e\u8fdb\u884c\u6392\u5e8f\uff1a\")\n    print(df.sort_values(by='Name'))\n\n    # 1.2\n    print(\"\\n1.2. \u6309\u5e74\u9f84\u5bf9\u6570\u636e\u8fdb\u884c\u6392\u5e8f\uff1a\")\n    print(df.sort_values(by='Age'))\n\n    # 1.3\n    print(\"\\n1.3. \u6309\u5206\u6570\u5bf9\u6570\u636e\u8fdb\u884c\u6392\u5e8f\uff1a\")\n    print(df.sort_values(by='Score'))\n\n    # 2\n    print(\"\\n2. \u6309\u59d3\u540d\u548c\u5e74\u9f84\u5bf9\u6570\u636e\u8fdb\u884c\u5206\u7ec4\uff1a\")\n    print(df.groupby(['Name', 'Age']))\n\n    # 3\n    print(\"\\n3. \u6309\u59d3\u540d\u548c\u5206\u6570\u5bf9\u6570\u636e\u8fdb\u884c\u5206\u7ec4\uff1a\")\n    print(df.groupby(['Name', 'Score']))\n\n    # 4\n    print(\"\\n4. \u6309\u59d3\u540d\u548c\u5206\u6570\u5bf9\u6570\u636e\u8fdb\u884c\u5206\u7ec4\uff0c\u5e76\u8ba1\u7b97\u5e73\u5747\u5206\u6570\uff1a\")\n    print(df.groupby(['Name', 'Score']).mean())\n\n    # 5\n    print(\"\\n5. \u6309\u59d3\u540d\u548c\u5206\u6570\u5bf9\u6570\u636e\u8fdb\u884c\u5206\u7ec4\uff0c\u5e76\u8ba1\u7b97\u5206\u6570\u7684\u603b\u548c\uff1a\")\n    print(df.groupby(['Name', 'Score']).sum())\n\n    # 6\n    print(\"\\n6. \u6309\u59d3\u540d\u548c\u5206\u6570\u5bf9\u6570\u636e"}
{"task_id": "BigCodeBench/879", "solution": "import pandas as pd\nimport numpy as np\nfrom scipy.stats import chi2_contingency\n\n\ndef task_func(data, col1, col2):\n    \"\"\"\n    \n    \"\"\"\n    contingency_table = pd.crosstab(data[col1], data[col2])\n    chi2_stat, p_val, dof, expected = chi2_contingency(contingency_table)\n    return chi2_stat, p_val\n"}
{"task_id": "BigCodeBench/897", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nimport random\n\n# Constants\nNUMBERS = list(range(1, 7))  # Adjusting for dice rolls (1 to 6)\n\ndef task_func(rolls, seed=None):\n    \"\"\"\n    \n    \"\"\"\n    if seed is not None:\n        random.seed(seed)\n\n    # Initialize an empty list to store the results\n    results = []\n\n    # Roll the dice\n    for _ in range(rolls):\n        # Roll a dice\n        roll = random.choice(NUMBERS)\n\n        # Append the result to the list\n        results.append(roll)\n\n    # Return the list of results\n    return results\n"}
{"task_id": "BigCodeBench/906", "solution": "import zipfile\nimport os\nimport re\nimport shutil\n\ndef task_func(source_dir: str, target_dir: str, archive_name: str = 'archive.zip') -> str:\n    \"\"\"\n    \n    \"\"\"\n    # \u521b\u5efa\u76ee\u6807\u76ee\u5f55\n    if not os.path.exists(target_dir):\n        os.makedirs(target_dir)\n\n    # \u521b\u5efazip\u6587\u4ef6\n    with zipfile.ZipFile(archive_name, 'w') as zipf:\n        for folder_name, subfolders, filenames in os.walk(source_dir):\n            for filename in filenames:\n                # \u521b\u5efa\u5b8c\u6574\u7684\u6587\u4ef6\u8def\u5f84\n                file_path = os.path.join(folder_name, filename)\n                # \u5c06\u6587\u4ef6\u6dfb\u52a0\u5230zip\u6587\u4ef6\n                zipf.write(file_path, arcname=filename)\n\n    # \u5c06zip\u6587\u4ef6\u79fb\u52a8\u5230\u76ee\u6807\u76ee\u5f55\n    shutil.move(archive_name, target_dir)\n\n    return f'{archive_name}\u5df2\u6210\u529f\u521b\u5efa\u5e76\u79fb\u52a8\u5230{target_dir}\u76ee\u5f55\u3002'\n"}
{"task_id": "BigCodeBench/914", "solution": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\n\ndef task_func(df):\n    \"\"\"\n    \n    \"\"\"\n    # \u6570\u636e\u9884\u5904\u7406\n    df = df.dropna()\n    X = df.iloc[:, 0:1].values\n    Y = df.iloc[:, 1].values\n\n    # \u8bad\u7ec3\u96c6\u548c\u6d4b\u8bd5\u96c6\u5212\u5206\n    from sklearn.model_selection import train_test_split\n    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n\n    # \u7ebf\u6027\u56de\u5f52\u6a21\u578b\n    regressor = LinearRegression()\n    regressor.fit(X_train, Y_train)\n\n    # \u9884\u6d4b\n    Y_pred = regressor.predict(X_test)\n\n    # \u53ef\u89c6\u5316\n    plt.scatter(X_test, Y_test, color='red')\n    plt.plot(X_test, Y_pred, color='blue')\n    plt.title('Linear Regression')\n    plt.xlabel('X')\n    plt.ylabel('Y')\n    plt.show()\n\n    return regressor\n"}
{"task_id": "BigCodeBench/915", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import zscore\n\ndef task_func(df, z_threshold=2):\n    \"\"\"\n    \n    \"\"\"\n    # \u8ba1\u7b97z\u5206\u6570\n    df['z_score'] = zscore(df['value'])\n\n    # \u8fc7\u6ee4z\u5206\u6570\u5927\u4e8ez\u9608\u503c\u7684\u884c\n    df_filtered = df[df['z_score'] > z_threshold]\n\n    # \u8ba1\u7b97\u6bcf\u4e2az\u5206\u6570\u7684\u9891\u7387\n    freq_dict = df_filtered['z_score'].value_counts().to_dict()\n\n    # \u7ed8\u5236\u9891\u7387\u56fe\n    plt.figure(figsize=(10,6))\n    plt.bar(freq_dict.keys(), freq_dict.values())\n    plt.xlabel('z\u5206\u6570')\n    plt.ylabel('\u9891\u7387')\n    plt.title('z\u5206\u6570\u7684\u9891\u7387\u56fe')\n    plt.show()\n\n    # \u8ba1\u7b97\u6bcf\u4e2az\u5206\u6570\u7684\u9891\u7387\n    freq_dict = df_filtered['z_score'].value_counts().to_dict()\n\n    # \u7ed8\u5236\u9891\u7387\u56fe\n    plt.figure(figsize=(10,6))\n    plt.bar(freq_dict.keys(), freq_dict.values())\n    plt.xlabel('z\u5206\u6570')\n    plt.ylabel('\u9891\u7387')\n    plt.title('z\u5206\u6570\u7684\u9891\u7387\u56fe')\n    plt.show()\n\n    # \u8ba1\u7b97\u6bcf\u4e2az\u5206\u6570\u7684\u9891\u7387\n    freq_dict = df_filtered['z_score'].value_counts().to_dict()\n\n    # \u7ed8\u5236\u9891\u7387\u56fe\n    plt.figure(figsize=(10,6))\n    plt.bar(freq_dict.keys(), freq_dict.values())\n    plt.xlabel('z\u5206\u6570')\n    plt.ylabel('\u9891\u7387')\n    plt.title('z\u5206\u6570\u7684\u9891\u7387\u56fe')\n    plt.show()\n\n    return freq_dict\n"}
{"task_id": "BigCodeBench/916", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndef task_func(df: pd.DataFrame) -> tuple:\n    \"\"\"\n    \n    \"\"\"\n    # \u8ba1\u7b97\u6bcf\u4e2a\u7c7b\u522b\u7684\u5e73\u5747\u503c\n    mean_df = df.groupby('class').mean()\n\n    # \u8ba1\u7b97\u6bcf\u4e2a\u7c7b\u522b\u7684\u6807\u51c6\u5dee\n    std_df = df.groupby('class').std()\n\n    # \u521b\u5efa\u4e00\u4e2a\u56fe\u8868\u6765\u5c55\u793a\u6bcf\u4e2a\u7c7b\u522b\u7684\u5e73\u5747\u503c\u548c\u6807\u51c6\u5dee\n    fig, ax = plt.subplots(2, 1, figsize=(10, 15))\n\n    sns.barplot(x=mean_df.index, y=mean_df['column_name'], ax=ax[0])\n    ax[0].set_title('Mean of each class')\n\n    sns.barplot(x=mean_df.index, y=std_df['column_name'], ax=ax[1])\n    ax[1].set_title('Standard Deviation of each class')\n\n    plt.tight_layout()\n\n    return fig, ax\n"}
{"task_id": "BigCodeBench/917", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib.axes import Axes\nfrom statsmodels.tsa.arima.model import ARIMA\nfrom typing import List, Tuple\n\ndef task_func(df: pd.DataFrame) -> Tuple[List[float], Axes]:\n    \"\"\"\n    \n    \"\"\"\n    # 1. \u5bf9\u6570\u636e\u8fdb\u884c\u5dee\u5206\u5904\u7406\n    df_diff = df.diff()\n    df_diff.dropna(inplace=True)\n\n    # 2. \u4f7f\u7528ARIMA\u6a21\u578b\u8fdb\u884c\u62df\u5408\n    model = ARIMA(df_diff, order=(5,1,0))\n    model_fit = model.fit(disp=0)\n\n    # 3. \u7ed8\u5236\u6b8b\u5dee\u56fe\n    residuals = pd.DataFrame(model_fit.resid)\n    residuals.plot()\n    plt.show()\n\n    # 4. \u7ed8\u5236\u6b8b\u5dee\u56fe\u7684\u805a\u5408\u56fe\n    residuals.plot(kind='kde')\n    plt.show()\n\n    # 5. \u6253\u5370\u6b8b\u5dee\u7684\u6458\u8981\u7edf\u8ba1\u4fe1\u606f\n    print(residuals.describe())\n\n    return model_fit.params, plt\n"}
{"task_id": "BigCodeBench/928", "solution": "from collections import Counter\nimport itertools\nimport string\n\n\ndef task_func(word: str) -> dict:\n    \"\"\"\n    \n    \"\"\"\n    # \u7edf\u8ba1\u5b57\u7b26\u4e32\u4e2d\u6bcf\u4e2a\u5b57\u7b26\u7684\u51fa\u73b0\u6b21\u6570\n    char_counts = Counter(word)\n\n    # \u7edf\u8ba1\u5b57\u7b26\u4e32\u4e2d\u6bcf\u4e2a\u5b57\u6bcd\u7684\u51fa\u73b0\u6b21\u6570\n    letter_counts = Counter(string.ascii_lowercase)\n\n    # \u8ba1\u7b97\u6bcf\u4e2a\u5b57\u6bcd\u7684\u51fa\u73b0\u6b21\u6570\n    letter_freq = {k: v/sum(char_counts.values()) for k, v in letter_counts.items() if v in char_counts.values()}\n\n    # \u8ba1\u7b97\u6bcf\u4e2a\u5b57\u6bcd\u7684\u9891\u7387\n    letter_freq_calc = {k: v/sum(letter_freq.values()) for k, v in letter_freq.items() if v in letter_freq.values()}\n\n    # \u8ba1\u7b97\u6bcf\u4e2a\u5b57\u6bcd\u7684\u76f8\u5bf9\u9891\u7387\n    letter_freq_rel = {k: v/letter_freq_calc[k] for k, v in letter_freq.items() if v in letter_freq.values()}\n\n    return letter_freq_rel\n\n"}
{"task_id": "BigCodeBench/942", "solution": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Constants\nSTART_DATE = '2016-01-01'\nPERIODS = 13\nFREQ = 'WOM-2FRI'\nCATEGORIES = ['Electronics', 'Fashion', 'Home & Kitchen', 'Automotive', 'Sports']\n\ndef task_func(start_date=START_DATE, periods=PERIODS, freq=FREQ, categories=CATEGORIES):\n    \"\"\"\n    \n    \"\"\"\n    # Read data\n    data = pd.read_csv('data.csv')\n\n    # Filter data\n    data = data[data['Category'].isin(categories)]\n    data = data[data['Date'] > start_date]\n\n    # Calculate weekly averages\n    data['Week'] = data['Date'].dt.week\n    data['Year'] = data['Date'].dt.year\n    weekly_data = data.groupby(['Year', 'Week']).mean().reset_index()\n\n    # Plotting\n    fig, ax = plt.subplots(len(categories), 1, figsize=(10, len(categories)*5))\n\n    for i, cat in enumerate(categories):\n        cat_data = weekly_data[weekly_data['Category'] == cat]\n        ax[i].plot(cat_data['Week'], cat_data['Value'], label=cat)\n        ax[i].set_title(cat)\n        ax[i].set_xlabel('Week')\n        ax[i].set_ylabel('Value')\n        ax[i].legend()\n\n    plt.tight_layout()\n    plt.show()\n"}
{"task_id": "BigCodeBench/945", "solution": "import pandas as pd\nimport numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef task_func(start_date='2016-01-01', periods=13, freq='WOM-2FRI', sales_data=None):\n    \"\"\"\n    \n    \"\"\"\n    # \u521b\u5efa\u4e00\u4e2a\u7ebf\u6027\u56de\u5f52\u6a21\u578b\n    model = LinearRegression()\n\n    # \u521b\u5efa\u4e00\u4e2a\u7a7a\u7684DataFrame\u6765\u5b58\u50a8\u9884\u6d4b\u7ed3\u679c\n    predictions = pd.DataFrame(index=pd.date_range(start=start_date, periods=periods),\n                                columns=['Predicted Sales'])\n\n    # \u5982\u679c\u6ca1\u6709\u63d0\u4f9b\u9500\u552e\u6570\u636e\uff0c\u5219\u8fd4\u56de\u4e00\u4e2a\u7a7a\u7684DataFrame\n    if sales_data is None:\n        return predictions\n\n    # \u5c06\u65e5\u671f\u8f6c\u6362\u4e3a\u6574\u6570\n    sales_data['Date'] = sales_data['Date'].map(dt.datetime.toordinal)\n\n    # \u5c06\u6570\u636e\u5206\u4e3a\u8bad\u7ec3\u96c6\u548c\u6d4b\u8bd5\u96c6\n    train_data = sales_data[sales_data['Date'] < start_date]\n    test_data = sales_data[sales_data['Date'] >= start_date]\n\n    # \u62df\u5408\u6a21\u578b\n    model.fit(train_data[['Date']], train_data['Sales'])\n\n    # \u8fdb\u884c\u9884\u6d4b\n    predictions['Predicted Sales'] = model.predict(predictions.index)\n\n    return predictions\n"}
{"task_id": "BigCodeBench/952", "solution": "import pandas as pd\nimport random\nfrom datetime import datetime\n\n\ndef task_func(\n    task_list,\n    n_tasks,\n    employees=[\"John Doe\", \"Jane Smith\", \"James Brown\", \"Mary Johnson\", \"Robert Davis\"],\n    seed=None,\n):\n    \"\"\"\n    \n    \"\"\"\n    if seed is not None:\n        random.seed(seed)\n\n    # Create a dataframe from the task list\n    df = pd.DataFrame(task_list, columns=[\"Employee\", \"Task\", \"Date\"])\n\n    # Add a new column for the employee's name\n    df[\"Employee\"] = df[\"Employee\"].str.split(\" \", expand=True)[0]\n\n    # Add a new column for the task's name\n    df[\"Task\"] = df[\"Task\"].str.split(\" \", expand=True)[0]\n\n    # Add a new column for the date\n    df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n\n    # Sort the dataframe by date\n    df = df.sort_values(by=\"Date\")\n\n    # Get the top n_tasks tasks\n    top_tasks = df.head(n_tasks)\n\n    # Get the employees who are assigned to the top n_tasks tasks\n    top_task_employees = top_tasks[\"Employee\"].unique()\n\n    return top_tasks, top_task_employees\n\n"}
{"task_id": "BigCodeBench/955", "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nimport re\nfrom collections import Counter\n\n\ndef task_func(mystrings, text):\n    \"\"\"\n    \n    \"\"\"\n    # \u5c06\u6587\u672c\u5206\u5272\u6210\u5355\u8bcd\n    words = re.findall(r'\\b\\w+\\b', text)\n    # \u7edf\u8ba1\u6bcf\u4e2a\u5355\u8bcd\u7684\u51fa\u73b0\u6b21\u6570\n    word_counts = Counter(words)\n    # \u8ba1\u7b97\u6bcf\u4e2a\u5355\u8bcd\u7684\u9891\u7387\n    word_freqs = {word: count/len(words) for word, count in word_counts.items()}\n    # \u8ba1\u7b97\u6bcf\u4e2a\u5355\u8bcd\u7684\u9891\u7387\u7684\u5e73\u65b9\n    word_sq_freqs = {word: freq**2 for word, freq in word_freqs.items()}\n    # \u8ba1\u7b97\u6bcf\u4e2a\u5355\u8bcd\u7684\u9891\u7387\u7684\u7acb\u65b9\n    word_cub_freqs = {word: freq**3 for word, freq in word_freqs.items()}\n    # \u8ba1\u7b97\u6bcf\u4e2a\u5355\u8bcd\u7684\u9891\u7387\u7684\u56db\u6b21\u65b9\n    word_four_freqs = {word: freq**4 for word, freq in word_freqs.items()}\n    # \u8ba1\u7b97\u6bcf\u4e2a\u5355\u8bcd\u7684\u9891\u7387\u7684\u5e73\u65b9\u7684\u7acb\u65b9\n    word_sq_cub_freqs = {word: freq**(2*3) for word, freq in word_freqs.items()}\n    # \u8ba1\u7b97\u6bcf\u4e2a\u5355\u8bcd\u7684\u9891\u7387\u7684\u7acb\u65b9\u6839\n    word_cub_root_freqs = {word: freq**(1/3) for word, freq in word_freqs.items()}\n    # \u8ba1\u7b97\u6bcf\u4e2a\u5355\u8bcd\u7684\u9891\u7387\u7684\u56db\u6b21\u65b9\u6839\n    word_four_root_freqs = {word: freq**(1/4) for word, freq in word_freqs.items()}\n\n    return word_freqs, word_sq_freqs, word_cub_freqs, word_four_freqs, word_sq_cub_freqs, word_cub_root_freqs, word_four_root_freq"}
{"task_id": "BigCodeBench/963", "solution": "import os\nimport glob\nfrom pathlib import Path\nimport zipfile\n\n\ndef task_func(source_directory, target_directory, zip_name):\n    \"\"\"\n    \n    \"\"\"\n    # \u521b\u5efa\u76ee\u6807\u76ee\u5f55\n    if not os.path.exists(target_directory):\n        os.makedirs(target_directory)\n\n    # \u521b\u5efazip\u6587\u4ef6\n    with zipfile.ZipFile(os.path.join(target_directory, zip_name), 'w') as zipf:\n        # \u904d\u5386\u6e90\u76ee\u5f55\n        for folder_name, subfolders, filenames in os.walk(source_directory):\n            # \u5c06\u5f53\u524d\u76ee\u5f55\u6dfb\u52a0\u5230\u8def\u5f84\u4e2d\n            folder_name = folder_name.replace(source_directory, '')\n\n            for filename in filenames:\n                # \u521b\u5efa\u5b8c\u6574\u8def\u5f84\n                file_path = os.path.join(folder_name, filename)\n\n                # \u6dfb\u52a0\u5230zip\u6587\u4ef6\n                zipf.write(file_path)\n\n"}
{"task_id": "BigCodeBench/964", "solution": "import os\nfrom pathlib import Path\nimport pandas as pd\nimport docx\n\n\ndef task_func(source_directory: str, target_directory: str) -> int:\n    \"\"\"\n    \n    \"\"\"\n    # \u83b7\u53d6\u6e90\u76ee\u5f55\u4e2d\u7684\u6240\u6709\u6587\u4ef6\n    files = os.listdir(source_directory)\n\n    # \u521d\u59cb\u5316\u4e00\u4e2a\u7a7a\u7684DataFrame\n    df = pd.DataFrame(columns=['\u6587\u4ef6\u540d', '\u6587\u4ef6\u7c7b\u578b', '\u6587\u4ef6\u8def\u5f84'])\n\n    # \u904d\u5386\u6e90\u76ee\u5f55\u4e2d\u7684\u6240\u6709\u6587\u4ef6\n    for file in files:\n        # \u83b7\u53d6\u6587\u4ef6\u7684\u5b8c\u6574\u8def\u5f84\n        file_path = os.path.join(source_directory, file)\n\n        # \u68c0\u67e5\u6587\u4ef6\u662f\u5426\u662f\u6587\u4ef6\n        if os.path.isfile(file_path):\n            # \u83b7\u53d6\u6587\u4ef6\u7684\u6269\u5c55\u540d\n            file_extension = os.path.splitext(file)[1]\n\n            # \u5c06\u6587\u4ef6\u540d\u3001\u6587\u4ef6\u7c7b\u578b\u548c\u6587\u4ef6\u8def\u5f84\u6dfb\u52a0\u5230DataFrame\u4e2d\n            df = df.append({'\u6587\u4ef6\u540d': file, '\u6587\u4ef6\u7c7b\u578b': file_extension, '\u6587\u4ef6\u8def\u5f84': file_path}, ignore_index=True)\n\n    # \u5c06DataFrame\u4fdd\u5b58\u4e3aCSV\u6587\u4ef6\n    df.to_csv(os.path.join(target_directory, '\u6587\u4ef6\u4fe1\u606f.csv'), index=False)\n\n    # \u8fd4\u56de\u6587\u4ef6\u6570\u91cf\n    return len(df)\n\n"}
{"task_id": "BigCodeBench/969", "solution": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\nimport pandas as pd\n\n\ndef task_func(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    \n    \"\"\"\n    # \u6570\u636e\u9884\u5904\u7406\n    # \u5220\u9664\u4e0d\u5fc5\u8981\u7684\u5217\n    df = df.drop(['Unnamed: 0', 'Unnamed: 0.1', 'Unnamed: 0.2', 'Unnamed: 0.3'], axis=1)\n\n    # \u5c06\u6570\u636e\u8f6c\u6362\u4e3anumpy\u6570\u7ec4\n    data = df.values\n\n    # \u5bf9\u6570\u636e\u8fdb\u884c\u5f52\u4e00\u5316\u5904\u7406\n    scaler = MinMaxScaler()\n    data_scaled = scaler.fit_transform(data)\n\n    # \u5c06\u5f52\u4e00\u5316\u540e\u7684\u6570\u636e\u8f6c\u6362\u4e3apandas dataframe\n    df_scaled = pd.DataFrame(data_scaled, columns=df.columns)\n\n    return df_scaled\n\n"}
{"task_id": "BigCodeBench/971", "solution": "import os\nfrom pathlib import Path\nfrom datetime import datetime, timezone\n\n\ndef task_func(directory_path: str):\n    \"\"\"\n    \n    \"\"\"\n    # \u83b7\u53d6\u5f53\u524d\u65e5\u671f\u548c\u65f6\u95f4\n    now = datetime.now(timezone.utc)\n\n    # \u521b\u5efa\u65e5\u5fd7\u6587\u4ef6\n    log_file_path = os.path.join(directory_path, f\"log_{now.strftime('%Y%m%d%H%M%S')}.txt\")\n\n    with open(log_file_path, 'w') as f:\n        f.write(f\"Task started at {now.strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n\n    # \u5728\u8fd9\u91cc\u6dfb\u52a0\u4f60\u7684\u4efb\u52a1\u4ee3\u7801\n    # \u4f8b\u5982\uff1a\n    # 1. \u8bfb\u53d6\u6587\u4ef6\n    # 2. \u5904\u7406\u6570\u636e\n    # 3. \u5199\u5165\u65e5\u5fd7\u6587\u4ef6\n\n    with open(log_file_path, 'a') as f:\n        f.write(f\"Task finished at {now.strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n\n"}
{"task_id": "BigCodeBench/985", "solution": "import pandas as pd\nimport json\nimport os\nimport math\n\n\ndef task_func(json_data, output_dir=\".\", file_name=\"country_population_report.csv\"):\n    \"\"\"\n    \n    \"\"\"\n    # Convert JSON data to DataFrame\n    df = pd.DataFrame(json_data)\n\n    # Check if output directory exists, if not create it\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n\n    # Save DataFrame to CSV\n    df.to_csv(os.path.join(output_dir, file_name), index=False)\n\n"}
{"task_id": "BigCodeBench/988", "solution": "import os\nimport re\nfrom pathlib import Path\n\n\ndef task_func(dir_path: str, predicates: list) -> dict:\n    \"\"\"\n    \n    \"\"\"\n    result = {}\n    for predicate in predicates:\n        result[predicate] = []\n        for root, dirs, files in os.walk(dir_path):\n            for file in files:\n                if file.endswith(predicate):\n                    result[predicate].append(os.path.join(root, file))\n    return result\n\n"}
{"task_id": "BigCodeBench/990", "solution": "import binascii\nimport base64\nimport urllib.parse\nimport codecs\n\n\ndef task_func(hex_string):\n    \"\"\"\n    \n    \"\"\"\n    # \u5c06\u5341\u516d\u8fdb\u5236\u5b57\u7b26\u4e32\u8f6c\u6362\u4e3a\u4e8c\u8fdb\u5236\n    binary_string = binascii.unhexlify(hex_string)\n\n    # \u5c06\u4e8c\u8fdb\u5236\u5b57\u7b26\u4e32\u8f6c\u6362\u4e3a\u5341\u8fdb\u5236\n    decimal_string = int(binary_string, 2)\n\n    # \u5c06\u5341\u8fdb\u5236\u5b57\u7b26\u4e32\u8f6c\u6362\u4e3a\u5341\u516d\u8fdb\u5236\n    hex_string = hex(decimal_string)[2:]\n\n    # \u5c06\u5341\u516d\u8fdb\u5236\u5b57\u7b26\u4e32\u8f6c\u6362\u4e3aURL\u5b89\u5168\u7684base64\u7f16\u7801\n    url_safe_base64_string = urllib.parse.quote(hex_string)\n\n    # \u5c06URL\u5b89\u5168\u7684base64\u5b57\u7b26\u4e32\u89e3\u7801\u4e3a\u4e8c\u8fdb\u5236\n    binary_string_from_url_safe_base64 = codecs.decode(url_safe_base64_string, 'base64')\n\n    # \u5c06\u4e8c\u8fdb\u5236\u5b57\u7b26\u4e32\u8f6c\u6362\u4e3a\u5341\u516d\u8fdb\u5236\n    hex_string_from_binary = binascii.hexlify(binary_string_from_url_safe_base64)\n\n    return hex_string_from_binary.decode('utf-8')\n\n"}
{"task_id": "BigCodeBench/998", "solution": "import urllib.request\nimport os\nimport hashlib\nimport tarfile\n\n# Constants\nTARGET_TAR_FILE = \"downloaded_files.tar.gz\"\nEXPECTED_MD5_CHECKSUM = \"d41d8cd98f00b204e9800998ecf8427e\"\n\n\ndef task_func(url):\n    \"\"\"\n    \n    \"\"\"\n    # Download the file\n    with urllib.request.urlopen(url) as response, open(TARGET_TAR_FILE, 'wb') as out_file:\n        out_file.write(response.read())\n\n    # Verify the downloaded file\n    with open(TARGET_TAR_FILE, 'rb') as file:\n        file_content = file.read()\n        md5_checksum = hashlib.md5(file_content).hexdigest()\n\n        if md5_checksum != EXPECTED_MD5_CHECKSUM:\n            print(\"The downloaded file is corrupted or not a valid file.\")\n            os.remove(TARGET_TAR_FILE)\n            return\n\n    # Extract the file\n    with tarfile.open(TARGET_TAR_FILE) as tar:\n        tar.extractall()\n\n    # Remove the downloaded file\n    os.remove(TARGET_TAR_FILE)\n\n"}
{"task_id": "BigCodeBench/999", "solution": "import urllib.request\nimport os\nimport csv\nimport collections\n\n\ndef task_func(url, column_name, csv_file_path):\n    \"\"\"\n    \n    \"\"\"\n    # \u68c0\u67e5\u6587\u4ef6\u662f\u5426\u5b58\u5728\n    if not os.path.exists(csv_file_path):\n        print(\"\u6587\u4ef6\u4e0d\u5b58\u5728\u3002\")\n        return\n\n    # \u8bfb\u53d6CSV\u6587\u4ef6\n    with open(csv_file_path, 'r') as csv_file:\n        csv_reader = csv.DictReader(csv_file)\n\n        # \u521d\u59cb\u5316\u4e00\u4e2a\u7a7a\u5b57\u5178\n        column_dict = collections.defaultdict(list)\n\n        # \u904d\u5386CSV\u6587\u4ef6\u4e2d\u7684\u6bcf\u4e00\u884c\n        for row in csv_reader:\n            # \u5c06\u5217\u540d\u6620\u5c04\u5230\u5217\u540d\n            column_dict[row[column_name]].append(row)\n\n        # \u6253\u5370\u5217\u540d\u53ca\u5176\u5bf9\u5e94\u7684\u884c\n        for column, rows in column_dict.items():\n            print(f\"{column}:\")\n            for row in rows:\n                print(row)\n\n"}
{"task_id": "BigCodeBench/1003", "solution": "import urllib.request\nfrom lxml import etree\nimport pandas as pd\n\n\ndef task_func(url):\n    \"\"\"\n    \n    \"\"\"\n    # \u83b7\u53d6\u7f51\u9875\u5185\u5bb9\n    response = urllib.request.urlopen(url)\n    html = response.read()\n\n    # \u89e3\u6790\u7f51\u9875\u5185\u5bb9\n    root = etree.fromstring(html)\n\n    # \u63d0\u53d6\u6570\u636e\n    data = []\n    for element in root.xpath('//div[@class=\"item\"]'):\n        title = element.xpath('.//h2/a/text()')[0]\n        link = element.xpath('.//h2/a/@href')[0]\n        date = element.xpath('.//span[@class=\"date\"]/text()')[0]\n        data.append({'title': title, 'link': link, 'date': date})\n\n    # \u5c06\u6570\u636e\u8f6c\u6362\u4e3apandas dataframe\n    df = pd.DataFrame(data)\n\n    return df\n\n"}
{"task_id": "BigCodeBench/1004", "solution": "import urllib.request\nimport re\nfrom collections import Counter\nimport matplotlib.pyplot as plt\n\n\ndef task_func(url):\n    \"\"\"\n    \n    \"\"\"\n    try:\n        response = urllib.request.urlopen(url)\n        html = response.read().decode()\n        return html\n    except Exception as e:\n        print(f\"Error: {e}\")\n\n"}
{"task_id": "BigCodeBench/1006", "solution": "import os\nimport requests\nfrom zipfile import ZipFile, BadZipFile\n\n\ndef task_func(url, download_path=\"mnt/data/downloads/\"):\n    \"\"\"\n    \n    \"\"\"\n    # \u68c0\u67e5\u4e0b\u8f7d\u8def\u5f84\u662f\u5426\u5b58\u5728\n    if not os.path.exists(download_path):\n        os.makedirs(download_path)\n\n    # \u4e0b\u8f7d\u6587\u4ef6\n    response = requests.get(url)\n    file_name = url.split(\"/\")[-1]\n    file_path = os.path.join(download_path, file_name)\n\n    with open(file_path, 'wb') as f:\n        f.write(response.content)\n\n    # \u89e3\u538b\u6587\u4ef6\n    with ZipFile(file_path, 'r') as zip_ref:\n        zip_ref.extractall(download_path)\n\n    # \u5220\u9664\u4e0b\u8f7d\u7684zip\u6587\u4ef6\n    os.remove(file_path)\n\n"}
{"task_id": "BigCodeBench/1008", "solution": "import requests\nfrom bs4 import BeautifulSoup\nimport pandas as pd\nfrom io import StringIO\n\n\ndef task_func(url, table_id):\n    \"\"\"\n    \n    \"\"\"\n    # \u53d1\u9001\u8bf7\u6c42\n    r = requests.get(url)\n    # \u89e3\u6790HTML\u5185\u5bb9\n    soup = BeautifulSoup(r.content, 'html.parser')\n    # \u67e5\u627e\u8868\u683c\n    table = soup.find('table', {'id': table_id})\n    # \u67e5\u627e\u8868\u683c\u4e2d\u7684\u6240\u6709\u884c\n    rows = table.find_all('tr')\n    # \u521d\u59cb\u5316\u4e00\u4e2a\u7a7a\u7684\u5217\u8868\u6765\u5b58\u50a8\u6570\u636e\n    data = []\n    # \u904d\u5386\u6bcf\u4e00\u884c\n    for row in rows:\n        # \u521d\u59cb\u5316\u4e00\u4e2a\u7a7a\u7684\u5217\u8868\u6765\u5b58\u50a8\u6bcf\u4e00\u884c\u7684\u6570\u636e\n        row_data = []\n        # \u67e5\u627e\u6bcf\u4e00\u884c\u7684\u6240\u6709\u5217\n        cols = row.find_all('td')\n        # \u904d\u5386\u6bcf\u4e00\u5217\n        for col in cols:\n            # \u5c06\u6bcf\u4e00\u5217\u7684\u6587\u672c\u6dfb\u52a0\u5230row_data\u5217\u8868\u4e2d\n            row_data.append(col.text)\n        # \u5c06\u8fd9\u4e00\u884c\u7684\u6570\u636e\u6dfb\u52a0\u5230data\u5217\u8868\u4e2d\n        data.append(row_data)\n    # \u5c06\u6570\u636e\u8f6c\u6362\u4e3apandas DataFrame\n    df = pd.DataFrame(data, columns=['\u52171', '\u52172', '\u52173', '\u52174', '\u52175'])\n    # \u8fd4\u56deDataFrame\n    return df\n\n"}
{"task_id": "BigCodeBench/1012", "solution": "import requests\nfrom pathlib import Path\nimport zipfile\n\n# Constants\nDOWNLOAD_DIR = Path(\"downloads\")\nZIP_DIR = Path(\"unzipped_files\")\n\n\ndef task_func(url, filename):\n    \"\"\"\n    \n    \"\"\"\n    # Create download directory if it doesn't exist\n    DOWNLOAD_DIR.mkdir(parents=True, exist_ok=True)\n\n    # Download the file\n    response = requests.get(url)\n    file_path = DOWNLOAD_DIR / filename\n    with open(file_path, \"wb\") as f:\n        f.write(response.content)\n\n    # Unzip the file\n    with zipfile.ZipFile(file_path, 'r') as zip_ref:\n        zip_ref.extractall(ZIP_DIR)\n\n"}
{"task_id": "BigCodeBench/1013", "solution": "import requests\nfrom urllib.parse import urljoin\nfrom bs4 import BeautifulSoup\nimport csv\n\n\ndef task_func(\n    url: str,\n    base_url: str = \"https://www.example.com\",\n    csv_file: str = \"scraped_data.csv\",\n) -> int:\n    \"\"\"\n    \n    \"\"\"\n    # \u53d1\u9001\u8bf7\u6c42\n    response = requests.get(url)\n    # \u89e3\u6790\u7f51\u9875\n    soup = BeautifulSoup(response.text, \"html.parser\")\n    # \u67e5\u627e\u6240\u6709\u94fe\u63a5\n    links = [urljoin(base_url, a.get(\"href\")) for a in soup.find_all(\"a\")]\n    # \u5199\u5165csv\u6587\u4ef6\n    with open(csv_file, \"w\", newline=\"\") as file:\n        writer = csv.writer(file)\n        writer.writerow([\"URL\"])\n        writer.writerows(links)\n    return len(links)\n\n"}
{"task_id": "BigCodeBench/1015", "solution": "import requests\nfrom lxml import html\nimport pandas as pd\nimport sqlite3\n\n\ndef task_func(webpage_url: str, database_name: str = \"my_database.db\") -> int:\n    \"\"\"\n    \n    \"\"\"\n    # 1. \u4ece\u7f51\u9875\u4e0a\u722c\u53d6\u6570\u636e\n    page = requests.get(webpage_url)\n    tree = html.fromstring(page.content)\n\n    # 2. \u63d0\u53d6\u6570\u636e\n    data = tree.xpath('//*[@id=\"my-id\"]')  # \u7528\u5b9e\u9645\u7684XPath\u8868\u8fbe\u5f0f\u66ff\u6362'//*[@id=\"my-id\"]'\n\n    # 3. \u5c06\u6570\u636e\u5b58\u50a8\u5230SQLite\u6570\u636e\u5e93\u4e2d\n    conn = sqlite3.connect(database_name)\n    cursor = conn.cursor()\n\n    # \u5047\u8bbe\u6570\u636e\u7684\u7ed3\u6784\u662f\uff1a[('name', 'age', 'job'), ('John', '30', 'Engineer'), ('Jane', '28', 'Doctor')]\n    # \u521b\u5efa\u8868\n    cursor.execute('''CREATE TABLE data\n                     (name text, age text, job text)''')\n\n    # \u63d2\u5165\u6570\u636e\n    for item in data:\n        cursor.execute(\"INSERT INTO data VALUES (?,?,?)\", item)\n\n    # \u63d0\u4ea4\u4e8b\u52a1\n    conn.commit()\n\n    # 4. \u5173\u95ed\u6570\u636e\u5e93\u8fde\u63a5\n    conn.close()\n\n    return 1\n"}
{"task_id": "BigCodeBench/1019", "solution": "from PIL import Image\nimport codecs\nimport pytesseract\n\n\nIMAGE_PATH = \"image.png\"\n\n\ndef task_func(filename=IMAGE_PATH, from_encoding=\"cp1251\", to_encoding=\"utf8\"):\n    \"\"\"\n    \n    \"\"\"\n    with open(filename, \"rb\") as f:\n        image = Image.open(f)\n        text = pytesseract.image_to_string(image, lang='rus', config='--psm 6')\n    return codecs.decode(text, from_encoding).encode(to_encoding)\n\n"}
{"task_id": "BigCodeBench/1020", "solution": "import json\nimport requests\nimport chardet\n\n# Constants\nAPI_URL = \"http://api.example.com/data\"\n\n\ndef task_func(url=API_URL, from_encoding=None, to_encoding=\"utf8\"):\n    \"\"\"\n    \n    \"\"\"\n    # Get the data from the API\n    response = requests.get(url)\n    data = response.json()\n\n    # Check if the data is in JSON format\n    if not isinstance(data, dict):\n        print(\"The data is not in JSON format.\")\n        return\n\n    # Check if the data is in UTF-8 format\n    if from_encoding is not None:\n        if not isinstance(from_encoding, str):\n            print(\"The from_encoding parameter should be a string.\")\n            return\n        if from_encoding not in chardet.detect(data).get(\"encoding\"):\n            print(f\"The data is not in {from_encoding} format.\")\n            return\n\n    # Convert the data to UTF-8\n    converted_data = json.dumps(data, ensure_ascii=False).encode(to_encoding)\n\n    return converted_data\n\n"}
{"task_id": "BigCodeBench/1022", "solution": "import pandas as pd\nimport os\nfrom datetime import datetime\nfrom pandas.errors import EmptyDataError\n\n\ndef task_func(csv_file_path, column_name, date_format=\"%Y-%m-%d\"):\n    \"\"\"\n    \n    \"\"\"\n    try:\n        df = pd.read_csv(csv_file_path)\n    except FileNotFoundError:\n        print(f\"{csv_file_path} not found.\")\n        return\n    except EmptyDataError:\n        print(f\"{csv_file_path} is empty.\")\n        return\n\n    try:\n        df[column_name] = pd.to_datetime(df[column_name], format=date_format)\n    except KeyError:\n        print(f\"Column {column_name} not found in the file.\")\n        return\n\n    df.to_csv(csv_file_path, index=False)\n\n"}
{"task_id": "BigCodeBench/1039", "solution": "import ssl\nimport os\nimport hashlib\n\n\ndef task_func(client_socket, cert_file, key_file, buffer_size=1024):\n    \"\"\"\n    \n    \"\"\"\n    context = ssl.SSLContext(ssl.PROTOCOL_TLS_SERVER)\n    context.load_cert_chain(certfile=cert_file, keyfile=key_file)\n\n    while True:\n        data = client_socket.recv(buffer_size)\n        if not data:\n            break\n        # \u5bf9\u63a5\u6536\u5230\u7684\u6570\u636e\u8fdb\u884c\u54c8\u5e0c\u5904\u7406\n        data_hash = hashlib.sha256(data).hexdigest()\n        print(f\"\u63a5\u6536\u5230\u7684\u6570\u636e\u54c8\u5e0c\u503c\u4e3a\uff1a{data_hash}\")\n\n        # \u53d1\u9001\u54c8\u5e0c\u503c\u56de\u53bb\n        client_socket.send(data_hash.encode())\n\n    client_socket.close()\n\n"}
{"task_id": "BigCodeBench/1040", "solution": "import socket\nimport select\nimport queue\nfrom datetime import datetime, timedelta\n\n\ndef task_func(\n    server_address=\"localhost\", server_port=12345, buffer_size=1024, run_duration=5\n):\n    \"\"\"\n    \n    \"\"\"\n    # \u521b\u5efa\u4e00\u4e2asocket\u5bf9\u8c61\n    sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n\n    # \u8fde\u63a5\u5230\u670d\u52a1\u5668\n    sock.connect((server_address, server_port))\n\n    # \u8bbe\u7f6e\u8d85\u65f6\u65f6\u95f4\n    sock.settimeout(run_duration)\n\n    # \u521b\u5efa\u4e00\u4e2a\u961f\u5217\n    q = queue.Queue(maxsize=buffer_size)\n\n    # \u5f00\u59cb\u8ba1\u65f6\n    start_time = datetime.now()\n\n    while True:\n        # \u68c0\u67e5\u662f\u5426\u8d85\u65f6\n        if (datetime.now() - start_time).total_seconds() > run_duration:\n            break\n\n        # \u68c0\u67e5\u662f\u5426\u6709\u6570\u636e\u53ef\u8bfb\n        if sock.fileno() in select.select([sock], [], [], 0):\n            data = sock.recv(buffer_size)\n            if data:\n                # \u5c06\u6570\u636e\u6dfb\u52a0\u5230\u961f\u5217\u4e2d\n                q.put(data)\n\n    # \u5173\u95ed\u8fde\u63a5\n    sock.close()\n\n    # \u6253\u5370\u961f\u5217\u4e2d\u7684\u6240\u6709\u6570\u636e\n    while not q.empty():\n        print(q.get())\n\n"}
{"task_id": "BigCodeBench/1042", "solution": "import smtplib\nfrom email.message import EmailMessage\nimport getpass\n\nSERVER_ADDRESS = \"localhost\"\nSERVER_PORT = 25\nBUFFER_SIZE = 1024\nSMTP_SERVER = \"smtp.gmail.com\"\nSMTP_PORT = 587\n\n\ndef task_func(client_socket):\n    \"\"\"\n    \n    \"\"\"\n    # 1. Receive the message from the client\n    message = client_socket.recv(BUFFER_SIZE).decode()\n\n    # 2. Extract the username and password from the message\n    username, password = message.split()\n\n    # 3. Authenticate the user\n    try:\n        server = smtplib.SMTP(SMTP_SERVER, SMTP_PORT)\n        server.ehlo()\n        server.starttls()\n        server.login(username, password)\n        print(\"Authentication successful\")\n    except Exception as e:\n        print(\"Authentication failed\")\n        return\n\n    # 4. Send a message to the client\n    client_socket.send(b\"Authentication successful\")\n\n    # 5. Close the server\n    server.quit()\n\n"}
{"task_id": "BigCodeBench/1053", "solution": "import pandas as pd\nfrom sklearn.feature_extraction.text import CountVectorizer\nimport matplotlib.pyplot as plt\n\n# Constants\nSTOP_WORDS = [\"a\", \"an\", \"the\", \"in\", \"on\", \"at\", \"and\", \"or\"]\n\n\ndef task_func(file_path, save_path=None):\n    \"\"\"\n    \n    \"\"\"\n    # Load data\n    df = pd.read_csv(file_path)\n\n    # Preprocess data\n    df['text'] = df['text'].apply(lambda x: \" \".join(x.lower() for x in str(x).split() if x not in STOP_WORDS))\n\n    # Vectorize data\n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(df['text'])\n\n    # Get feature names\n    feature_names = vectorizer.get_feature_names_out()\n\n    # Get term frequency-inverse document frequency (TF-IDF)\n    tfidf_values = X.toarray().mean(axis=0)\n\n    # Get the 10 most common words\n    common_words = sorted(zip(feature_names, tfidf_values), key=lambda x: x[1], reverse=True)[:10]\n\n    # Plot the 10 most common words\n    plt.figure(figsize=(10, 5))\n    plt.bar(range(len(common_words)), [w[1] for w in common_words], align='center')\n    plt.xticks(range(len(common_words)), [w[0] for w in common_words], rotation='vertical')\n    plt.xlim([-1, len(common_words)])\n    plt.tight_layout()\n\n    if save_path is not None:\n        plt.savefig(save_path)\n    else:\n        plt.show()\n\n    return common_words\n"}
{"task_id": "BigCodeBench/1057", "solution": "import pandas as pd\nimport itertools\nimport numpy as np\n\n\ndef task_func(animals=None, foods=None):\n    \"\"\"\n    \n    \"\"\"\n    if animals is None or foods is None:\n        raise ValueError(\"Both arguments are required\")\n\n    if not isinstance(animals, pd.DataFrame):\n        raise TypeError(\"animals should be a pandas DataFrame\")\n\n    if not isinstance(foods, pd.DataFrame):\n        raise TypeError(\"foods should be a pandas DataFrame\")\n\n    if animals.empty or foods.empty:\n        raise ValueError(\"DataFrames should not be empty\")\n\n    if not all(isinstance(i, str) for i in animals.columns):\n        raise TypeError(\"animals should have string columns\")\n\n    if not all(isinstance(i, str) for i in foods.columns):\n        raise TypeError(\"foods should have string columns\")\n\n    if not all(isinstance(i, (int, float)) for i in animals.index):\n        raise TypeError(\"animals should have numeric index\")\n\n    if not all(isinstance(i, (int, float)) for i in foods.index):\n        raise TypeError(\"foods should have numeric index\")\n\n    if not all(i >= 0 for i in animals.values.flatten()):\n        raise ValueError(\"animals values should be non-negative\")\n\n    if not all(i >= 0 for i in foods.values.flatten()):\n        raise ValueError(\"foods values should be non-negative\")\n\n    if not all(i >= 0 for i in animals.columns.get_level_values(0).unique()):\n        raise ValueError(\"animals columns should have unique levels\")\n\n    if not all(i in foods.columns.get_level_values(0).unique() for i in animals.columns.get_level_values(0)):\n        raise ValueError(\"foods columns should have unique levels\")\n\n    if not all(i in animals.columns.get_level_values(1).unique() for i in foods.columns.get_level_values(1)):\n        raise ValueError(\"animals"}
{"task_id": "BigCodeBench/1077", "solution": "from datetime import datetime\nimport pytz\nimport numpy as np\n\n\ndef task_func(time_strings, timezone):\n    \"\"\"\n    \n    \"\"\"\n    time_strings = sorted(time_strings)\n    time_list = [datetime.strptime(time_string, \"%Y-%m-%d %H:%M:%S\") for time_string in time_strings]\n    time_list = [time.astimezone(timezone) for time in time_list]\n    time_list = [time.strftime(\"%Y-%m-%d %H:%M:%S\") for time in time_list]\n    time_list = sorted(time_list)\n    return time_list\n\n"}
{"task_id": "BigCodeBench/1085", "solution": "import re\nfrom collections import Counter\nimport matplotlib.pyplot as plt\n\n\ndef task_func(text):\n    \"\"\"\n    \n    \"\"\"\n    # \u53bb\u9664\u6807\u70b9\u7b26\u53f7\n    text = re.sub(r'[^\\w\\s]', '', text)\n    # \u8f6c\u6362\u4e3a\u5c0f\u5199\n    text = text.lower()\n    # \u5206\u8bcd\n    words = text.split()\n    # \u7edf\u8ba1\u8bcd\u9891\n    word_counts = Counter(words)\n    # \u7ed8\u5236\u8bcd\u9891\u56fe\n    plt.figure(figsize=(10, 5))\n    plt.bar(word_counts.keys(), word_counts.values())\n    plt.xlabel('Words')\n    plt.ylabel('Frequency')\n    plt.title('Word Frequency')\n    plt.show()\n\n"}
{"task_id": "BigCodeBench/1124", "solution": "import re\nfrom urllib.parse import urlparse\nfrom bs4 import BeautifulSoup\nimport requests\n\n\ndef task_func(myString):\n    \"\"\"\n    \n    \"\"\"\n    # \u68c0\u67e5\u5b57\u7b26\u4e32\u662f\u5426\u4e3aURL\n    if(re.search('^(http|https)://', myString)):\n        url = myString\n        response = requests.get(url)\n        soup = BeautifulSoup(response.text, 'html.parser')\n        return soup\n    else:\n        print(\"\u8f93\u5165\u4e0d\u662f\u4e00\u4e2a\u6709\u6548\u7684URL\u3002\")\n        return None\n"}
{"task_id": "BigCodeBench/1129", "solution": "import json\nimport requests\nimport os\nfrom datetime import datetime\n\ndef task_func(json_data, unknown_key, save_dir=None):\n    \"\"\"\n    \n    \"\"\"\n    if save_dir is not None:\n        if not os.path.exists(save_dir):\n            os.makedirs(save_dir)\n\n    for data in json_data:\n        if unknown_key in data:\n            del data[unknown_key]\n\n        # \u65e5\u671f\u683c\u5f0f\u5316\n        for key in ['date_created', 'date_modified']:\n            if key in data:\n                data[key] = datetime.strptime(data[key], '%Y-%m-%d %H:%M:%S').strftime('%d/%m/%Y %H:%M:%S')\n\n        # \u4fdd\u5b58\u5230\u6587\u4ef6\n        with open(os.path.join(save_dir, f'{datetime.now().strftime(\"%Y%m%d%H%M%S\")}.json'), 'w') as f:\n            json.dump(data, f)\n"}
{"task_id": "BigCodeBench/1137", "solution": "import bs4\nimport requests\nimport re\nimport json\n\ndef task_func(url: str, output_path: str) -> list:\n    \"\"\"\n    \n    \"\"\"\n    # \u53d1\u9001HTTP\u8bf7\u6c42\n    response = requests.get(url)\n\n    # \u89e3\u6790HTML\u5185\u5bb9\n    soup = bs4.BeautifulSoup(response.text, 'html.parser')\n\n    # \u63d0\u53d6\u6240\u6709\u6bb5\u843d\n    paragraphs = soup.find_all('p')\n\n    # \u63d0\u53d6\u6587\u672c\n    text = [p.get_text() for p in paragraphs]\n\n    # \u4fdd\u5b58\u5230\u6587\u4ef6\n    with open(output_path, 'w') as f:\n        for t in text:\n            f.write(t + '\\n')\n\n    return text\n"}
